{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block\" style=\"border: 2px solid #1976D2;background-color:#E3F2FD;padding:5px;font-size:0.9em;\">\n",
    "본 자료는 저작권법 제25조 2항에 의해 보호를 받습니다. 본 자료를 외부에 공개하지 말아주세요.<br>\n",
    "본 강의만 잘 정리하면, 데이터 분석과 데이터 과학(머신러닝, 인공지능) 모두 가능합니다!<br>\n",
    "<b><a href=\"https://school.fun-coding.org/\">잔재미코딩</a> 에서 본 강의 기반 최적화된 로드맵도 확인하실 수 있습니다</b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## raw data를 pandas와 파이썬으로 조작해서 그래프 만들어보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 데이터 시각화란?\n",
    "- 데이터 분석 결과를 쉽게 이해할 수 있도록 시각적으로 표현하고 전달되는 과정\n",
    "- 탐색적 데이터 분석, 데이터 처리, 데이터 예측 모든 경우, 결과를 알아보기 쉽게 하기 위해 데이터 시각화는 필수적임\n",
    "- 다양한 시각화 기법 중, 가장 최신의 흥미로운 데이터 시각화 과정을 진행해보기로 함\n",
    "  - https://app.flourish.studio\n",
    "  - https://public.flourish.studio/visualisation/2897018/\n",
    "\n",
    "### 지금까지 익힌 데이터 처리 기술을 기반으로 데이터 시각화를 위해, raw data를 포멧에 맞추어 변환하여 그래프를 만들어보기로 함\n",
    "<img src=\"https://www.fun-coding.org/00_Images/covid_graph_ex2.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 데이터 시각화를 위한 데이터 포멧 이해\n",
    "- 데이터 시각화를 위해, raw data를 변환해야 함\n",
    "- 지금까지 익힌 데이터 처리 기술을 사용해서, 데이터를 변환하기로 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 필요 데이터\n",
    "  - 국가명, 국기, 날짜별 확진자 수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.fun-coding.org/00_Images/covid_ex_data_format.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. raw data 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Admin2</th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Last_Update</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long_</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>Active</th>\n",
       "      <th>Combined_Key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45001.0</td>\n",
       "      <td>Abbeville</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-04-01 21:58:49</td>\n",
       "      <td>34.223334</td>\n",
       "      <td>-82.461707</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Abbeville, South Carolina, US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22001.0</td>\n",
       "      <td>Acadia</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-04-01 21:58:49</td>\n",
       "      <td>30.295065</td>\n",
       "      <td>-92.414197</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>Acadia, Louisiana, US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51001.0</td>\n",
       "      <td>Accomack</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-04-01 21:58:49</td>\n",
       "      <td>37.767072</td>\n",
       "      <td>-75.632346</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>Accomack, Virginia, US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16001.0</td>\n",
       "      <td>Ada</td>\n",
       "      <td>Idaho</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-04-01 21:58:49</td>\n",
       "      <td>43.452658</td>\n",
       "      <td>-116.241552</td>\n",
       "      <td>195</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>192</td>\n",
       "      <td>Ada, Idaho, US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19001.0</td>\n",
       "      <td>Adair</td>\n",
       "      <td>Iowa</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-04-01 21:58:49</td>\n",
       "      <td>41.330756</td>\n",
       "      <td>-94.471059</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Adair, Iowa, US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      FIPS     Admin2  Province_State Country_Region          Last_Update  \\\n",
       "0  45001.0  Abbeville  South Carolina             US  2020-04-01 21:58:49   \n",
       "1  22001.0     Acadia       Louisiana             US  2020-04-01 21:58:49   \n",
       "2  51001.0   Accomack        Virginia             US  2020-04-01 21:58:49   \n",
       "3  16001.0        Ada           Idaho             US  2020-04-01 21:58:49   \n",
       "4  19001.0      Adair            Iowa             US  2020-04-01 21:58:49   \n",
       "\n",
       "         Lat       Long_  Confirmed  Deaths  Recovered  Active  \\\n",
       "0  34.223334  -82.461707          4       0          0       4   \n",
       "1  30.295065  -92.414197         47       1          0      46   \n",
       "2  37.767072  -75.632346          7       0          0       7   \n",
       "3  43.452658 -116.241552        195       3          0     192   \n",
       "4  41.330756  -94.471059          1       0          0       1   \n",
       "\n",
       "                    Combined_Key  \n",
       "0  Abbeville, South Carolina, US  \n",
       "1          Acadia, Louisiana, US  \n",
       "2         Accomack, Virginia, US  \n",
       "3                 Ada, Idaho, US  \n",
       "4                Adair, Iowa, US  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "PATH = \"COVID-19-master/csse_covid_19_data/csse_covid_19_daily_reports/\"\n",
    "doc = pd.read_csv(PATH + \"04-01-2020.csv\", encoding='utf-8-sig')\n",
    "doc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Last Update</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hubei</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>2020-03-01T10:13:19</td>\n",
       "      <td>66907</td>\n",
       "      <td>2761</td>\n",
       "      <td>31536</td>\n",
       "      <td>30.9756</td>\n",
       "      <td>112.2707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>2020-03-01T23:43:03</td>\n",
       "      <td>3736</td>\n",
       "      <td>17</td>\n",
       "      <td>30</td>\n",
       "      <td>36.0000</td>\n",
       "      <td>128.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Italy</td>\n",
       "      <td>2020-03-01T23:23:02</td>\n",
       "      <td>1694</td>\n",
       "      <td>34</td>\n",
       "      <td>83</td>\n",
       "      <td>43.0000</td>\n",
       "      <td>12.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Guangdong</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>2020-03-01T14:13:18</td>\n",
       "      <td>1349</td>\n",
       "      <td>7</td>\n",
       "      <td>1016</td>\n",
       "      <td>23.3417</td>\n",
       "      <td>113.4244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Henan</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>2020-03-01T14:13:18</td>\n",
       "      <td>1272</td>\n",
       "      <td>22</td>\n",
       "      <td>1198</td>\n",
       "      <td>33.8820</td>\n",
       "      <td>113.6140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province/State  Country/Region          Last Update  Confirmed  Deaths  \\\n",
       "0          Hubei  Mainland China  2020-03-01T10:13:19      66907    2761   \n",
       "1            NaN     South Korea  2020-03-01T23:43:03       3736      17   \n",
       "2            NaN           Italy  2020-03-01T23:23:02       1694      34   \n",
       "3      Guangdong  Mainland China  2020-03-01T14:13:18       1349       7   \n",
       "4          Henan  Mainland China  2020-03-01T14:13:18       1272      22   \n",
       "\n",
       "   Recovered  Latitude  Longitude  \n",
       "0      31536   30.9756   112.2707  \n",
       "1         30   36.0000   128.0000  \n",
       "2         83   43.0000    12.0000  \n",
       "3       1016   23.3417   113.4244  \n",
       "4       1198   33.8820   113.6140  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "PATH = \"COVID-19-master/csse_covid_19_data/csse_covid_19_daily_reports/\"\n",
    "doc = pd.read_csv(PATH + \"03-01-2020.csv\", encoding='utf-8-sig')\n",
    "doc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 3월 중순 데이터까지는 컬럼명이 Province/State, Country/Region 이고, 이후에는 Province_State, Country_Region 이므로, try except 구문을 사용해서, 데이터 조작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Confirmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anhui</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chongqing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fujian</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gansu</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province_State  Country_Region  Confirmed\n",
       "0          Anhui  Mainland China        1.0\n",
       "1        Beijing  Mainland China       14.0\n",
       "2      Chongqing  Mainland China        6.0\n",
       "3         Fujian  Mainland China        1.0\n",
       "4          Gansu  Mainland China        NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = pd.read_csv(PATH + \"01-22-2020.csv\", encoding='utf-8-sig')\n",
    "try:\n",
    "    doc = doc[['Province_State', 'Country_Region', 'Confirmed']]  # 1. 특정 컬럼만 선택해서 데이터프레임 만들기\n",
    "except:\n",
    "    doc = doc[['Province/State', 'Country/Region', 'Confirmed']]  # 1. 특정 컬럼만 선택해서 데이터프레임 만들기\n",
    "    doc.columns = ['Province_State', 'Country_Region', 'Confirmed']\n",
    "    \n",
    "doc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 데이터프레임 데이터 변환하기\n",
    "1. 특정 컬럼만 선택해서 데이터프레임 만들기\n",
    "2. 특정 컬럼에 없는 데이터 삭제하기\n",
    "3. 특정 컬럼의 데이터 타입 변경하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Confirmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anhui</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chongqing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fujian</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Guangdong</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province_State  Country_Region  Confirmed\n",
       "0          Anhui  Mainland China          1\n",
       "1        Beijing  Mainland China         14\n",
       "2      Chongqing  Mainland China          6\n",
       "3         Fujian  Mainland China          1\n",
       "5      Guangdong  Mainland China         26"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "PATH = \"COVID-19-master/csse_covid_19_data/csse_covid_19_daily_reports/\"\n",
    "\n",
    "doc = pd.read_csv(PATH + \"01-22-2020.csv\", encoding='utf-8-sig')\n",
    "try:\n",
    "    doc = doc[['Province_State', 'Country_Region', 'Confirmed']]  # 1. 특정 컬럼만 선택해서 데이터프레임 만들기\n",
    "except:\n",
    "    doc = doc[['Province/State', 'Country/Region', 'Confirmed']]  # 1. 특정 컬럼만 선택해서 데이터프레임 만들기\n",
    "    doc.columns = ['Province_State', 'Country_Region', 'Confirmed']\n",
    "doc = doc.dropna(subset=['Confirmed'])     # 2. 특정 컬럼에 없는 데이터 삭제하기\n",
    "doc = doc.astype({'Confirmed': 'int64'})   # 3. 특정 컬럼의 데이터 타입 변경하기\n",
    "doc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 국가 정보 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>UID</th>\n",
       "      <th>iso2</th>\n",
       "      <th>iso3</th>\n",
       "      <th>code3</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Admin2</th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long_</th>\n",
       "      <th>Combined_Key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Botswana</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Botswana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Burundi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Burundi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sierra Leone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sierra Leone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AF</td>\n",
       "      <td>AFG</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.93911</td>\n",
       "      <td>67.709953</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>ALB</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Albania</td>\n",
       "      <td>41.15330</td>\n",
       "      <td>20.168300</td>\n",
       "      <td>Albania</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0  UID iso2 iso3  code3  FIPS Admin2 Province_State  \\\n",
       "0             0           0  NaN   BW  NaN    NaN   NaN    NaN            NaN   \n",
       "1             1           1  NaN   BI  NaN    NaN   NaN    NaN            NaN   \n",
       "2             2           2  NaN   SL  NaN    NaN   NaN    NaN            NaN   \n",
       "3             3           3  4.0   AF  AFG    4.0   NaN    NaN            NaN   \n",
       "4             4           4  8.0   AL  ALB    8.0   NaN    NaN            NaN   \n",
       "\n",
       "  Country_Region       Lat      Long_  Combined_Key  \n",
       "0       Botswana       NaN        NaN      Botswana  \n",
       "1        Burundi       NaN        NaN       Burundi  \n",
       "2   Sierra Leone       NaN        NaN  Sierra Leone  \n",
       "3    Afghanistan  33.93911  67.709953   Afghanistan  \n",
       "4        Albania  41.15330  20.168300       Albania  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_info = pd.read_csv(\"COVID-19-master/csse_covid_19_data/UID_ISO_FIPS_LookUp_Table.csv\", encoding='utf-8-sig')\n",
    "country_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 두 데이터프레임 합쳐보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province_State_x</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>UID</th>\n",
       "      <th>iso2</th>\n",
       "      <th>iso3</th>\n",
       "      <th>code3</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Admin2</th>\n",
       "      <th>Province_State_y</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long_</th>\n",
       "      <th>Combined_Key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anhui</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chongqing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fujian</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Guangdong</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province_State_x  Country_Region  Confirmed  Unnamed: 0.1  Unnamed: 0  UID  \\\n",
       "0            Anhui  Mainland China          1           NaN         NaN  NaN   \n",
       "1          Beijing  Mainland China         14           NaN         NaN  NaN   \n",
       "2        Chongqing  Mainland China          6           NaN         NaN  NaN   \n",
       "3           Fujian  Mainland China          1           NaN         NaN  NaN   \n",
       "4        Guangdong  Mainland China         26           NaN         NaN  NaN   \n",
       "\n",
       "  iso2 iso3  code3  FIPS Admin2 Province_State_y  Lat  Long_ Combined_Key  \n",
       "0  NaN  NaN    NaN   NaN    NaN              NaN  NaN    NaN          NaN  \n",
       "1  NaN  NaN    NaN   NaN    NaN              NaN  NaN    NaN          NaN  \n",
       "2  NaN  NaN    NaN   NaN    NaN              NaN  NaN    NaN          NaN  \n",
       "3  NaN  NaN    NaN   NaN    NaN              NaN  NaN    NaN          NaN  \n",
       "4  NaN  NaN    NaN   NaN    NaN              NaN  NaN    NaN          NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.merge(doc, country_info, how='left', on='Country_Region')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 잘못 매칭된 국가 정보 확인하기\n",
    "  - iso2 컬럼이 매칭되지 않은 확진자수 국가 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Province_State_x     12\n",
       "Country_Region        0\n",
       "Confirmed             0\n",
       "Unnamed: 0.1         34\n",
       "Unnamed: 0           34\n",
       "UID                  34\n",
       "iso2                 34\n",
       "iso3                 34\n",
       "code3                34\n",
       "FIPS                140\n",
       "Admin2              196\n",
       "Province_State_y     65\n",
       "Lat                 139\n",
       "Long_               139\n",
       "Combined_Key         34\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province_State_x</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>UID</th>\n",
       "      <th>iso2</th>\n",
       "      <th>iso3</th>\n",
       "      <th>code3</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Admin2</th>\n",
       "      <th>Province_State_y</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long_</th>\n",
       "      <th>Combined_Key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anhui</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chongqing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fujian</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Guangdong</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province_State_x  Country_Region  Confirmed  Unnamed: 0.1  Unnamed: 0  UID  \\\n",
       "0            Anhui  Mainland China          1           NaN         NaN  NaN   \n",
       "1          Beijing  Mainland China         14           NaN         NaN  NaN   \n",
       "2        Chongqing  Mainland China          6           NaN         NaN  NaN   \n",
       "3           Fujian  Mainland China          1           NaN         NaN  NaN   \n",
       "4        Guangdong  Mainland China         26           NaN         NaN  NaN   \n",
       "\n",
       "  iso2 iso3  code3  FIPS Admin2 Province_State_y  Lat  Long_ Combined_Key  \n",
       "0  NaN  NaN    NaN   NaN    NaN              NaN  NaN    NaN          NaN  \n",
       "1  NaN  NaN    NaN   NaN    NaN              NaN  NaN    NaN          NaN  \n",
       "2  NaN  NaN    NaN   NaN    NaN              NaN  NaN    NaN          NaN  \n",
       "3  NaN  NaN    NaN   NaN    NaN              NaN  NaN    NaN          NaN  \n",
       "4  NaN  NaN    NaN   NaN    NaN              NaN  NaN    NaN          NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_rows = test_df[test_df['iso2'].isnull()]\n",
    "nan_rows.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 컬럼값 변경하기\n",
    "- Country_Region 국가명이 다양한 경우가 많았음\n",
    "- 각 케이스를 일괄적으로 변경할 키값이 존재하지 않고, 키가 될 수 있는 컬럼도 다양하고, 각 파일마다 키가 될 수 있는 컬럼이 변경되어, 키값으로 매칭이 불가하였음\n",
    "- 이에 각 케이스를 직접 확인해서, 국가명을 일관되게 변경할 수 있도록 별도 json 파일 작성\n",
    "- json 파일 기반으로 국가명을 일관되게 변경하기로 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### json.load() 함수로 파일로된 json 데이터를 사전처럼 다룰 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Mainland China', 'Macau', 'South Korea', 'Aruba', ' Azerbaijan', 'Bahamas, The', 'Cape Verde', 'Cayman Islands', 'Channel Islands', 'Curacao', 'Czech Republic', 'East Timor', 'Faroe Islands', 'French Guiana', 'Gambia, The', 'Gibraltar', 'Greenland', 'Guadeloupe', 'Guam', 'Guernsey', 'Hong Kong', 'Hong Kong SAR', 'Iran (Islamic Republic of)', 'Ivory Coast', 'Jersey', 'Macao SAR', 'Martinique', 'Mayotte', 'North Ireland', 'Palestine', 'Puerto Rico', 'Republic of Ireland', 'Republic of Korea', 'Republic of Moldova', 'Republic of the Congo', 'Reunion', 'Russian Federation', 'Saint Barthelemy', 'Saint Martin', 'St. Martin', 'Taipei and environs', 'The Bahamas', 'The Gambia', 'UK', 'Vatican City', 'Viet Nam', 'occupied Palestinian territory', 'Taiwan*', 'Malawi', 'South Sudan', 'Western Sahara', 'Namibia'])\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('COVID-19-master/csse_covid_19_data/country_convert.json', 'r', encoding='utf-8-sig') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "    print (json_data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### apply() 함수 사용법\n",
    "- apply() 함수를 사용해서, 특정 컬럼값 변경 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>영어</th>\n",
       "      <th>수학</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dave</th>\n",
       "      <td>60</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>David</th>\n",
       "      <td>70</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       영어   수학\n",
       "Dave   60  100\n",
       "David  70   50"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    '영어': [60, 70],\n",
    "    '수학': [100, 50]\n",
    "}, index = ['Dave', 'David'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(df_data):\n",
    "    print (type(df_data))    \n",
    "    print (df_data.index)\n",
    "    print (df_data.values)    \n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 참고로 행이 두개 인데, 3번 func가 호출되는 이유는 apply() 함수 자체가, 첫 번째 행에 대해서는 두번 호출하도록 구현되어 있기 때문임 (전체 행의 처리를 위한 최적화 기법 적용 가능 여부를 확인코자 이와 같이 구현됨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Index(['Dave', 'David'], dtype='object')\n",
      "[60 70]\n",
      "<class 'pandas.core.series.Series'>\n",
      "Index(['Dave', 'David'], dtype='object')\n",
      "[100  50]\n"
     ]
    }
   ],
   "source": [
    "df_func = df.apply(func, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Index(['영어', '수학'], dtype='object')\n",
      "[ 60 100]\n",
      "<class 'pandas.core.series.Series'>\n",
      "Index(['영어', '수학'], dtype='object')\n",
      "[70 50]\n"
     ]
    }
   ],
   "source": [
    "df_func = df.apply(func, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>영어</th>\n",
       "      <th>수학</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dave</th>\n",
       "      <td>60</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>David</th>\n",
       "      <td>70</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       영어   수학\n",
       "Dave   60  100\n",
       "David  70   50"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    '영어': [60, 70],\n",
    "    '수학': [100, 50]\n",
    "}, index = ['Dave', 'David'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(df_data):\n",
    "    df_data['영어'] = 80\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_func = df.apply(func, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>영어</th>\n",
       "      <th>수학</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dave</th>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>David</th>\n",
       "      <td>80</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       영어   수학\n",
       "Dave   80  100\n",
       "David  80   50"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### apply() 함수를 사용해서, 국가 컬럼값 변경하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 사전 작업 (doc 변수로 데이터프레임 파일 만들기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Confirmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anhui</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chongqing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fujian</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Guangdong</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province_State  Country_Region  Confirmed\n",
       "0          Anhui  Mainland China          1\n",
       "1        Beijing  Mainland China         14\n",
       "2      Chongqing  Mainland China          6\n",
       "3         Fujian  Mainland China          1\n",
       "5      Guangdong  Mainland China         26"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "doc = pd.read_csv(PATH + \"01-22-2020.csv\", encoding='utf-8-sig')\n",
    "try:\n",
    "    doc = doc[['Province_State', 'Country_Region', 'Confirmed']]  # 1. 특정 컬럼만 선택해서 데이터프레임 만들기\n",
    "except:\n",
    "    doc = doc[['Province/State', 'Country/Region', 'Confirmed']]  # 1. 특정 컬럼만 선택해서 데이터프레임 만들기\n",
    "    doc.columns = ['Province_State', 'Country_Region', 'Confirmed']\n",
    "doc = doc.dropna(subset=['Confirmed'])     # 2. 특정 컬럼에 없는 데이터 삭제하기\n",
    "doc = doc.astype({'Confirmed': 'int64'})   # 3. 특정 컬럼의 데이터 타입 변경하기\n",
    "doc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 변경할 국가명을 가지고 있는 json 파일 읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Mainland China', 'Macau', 'South Korea', 'Aruba', ' Azerbaijan', 'Bahamas, The', 'Cape Verde', 'Cayman Islands', 'Channel Islands', 'Curacao', 'Czech Republic', 'East Timor', 'Faroe Islands', 'French Guiana', 'Gambia, The', 'Gibraltar', 'Greenland', 'Guadeloupe', 'Guam', 'Guernsey', 'Hong Kong', 'Hong Kong SAR', 'Iran (Islamic Republic of)', 'Ivory Coast', 'Jersey', 'Macao SAR', 'Martinique', 'Mayotte', 'North Ireland', 'Palestine', 'Puerto Rico', 'Republic of Ireland', 'Republic of Korea', 'Republic of Moldova', 'Republic of the Congo', 'Reunion', 'Russian Federation', 'Saint Barthelemy', 'Saint Martin', 'St. Martin', 'Taipei and environs', 'The Bahamas', 'The Gambia', 'UK', 'Vatican City', 'Viet Nam', 'occupied Palestinian territory', 'Taiwan*', 'Malawi', 'South Sudan', 'Western Sahara', 'Namibia'])\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('COVID-19-master/csse_covid_19_data/country_convert.json', 'r', encoding='utf-8-sig') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "    print (json_data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Country_Region 이라는 컬럼값을 확인해서, 국가명이 다르게 기재되어 있을 경우에만, 지정한 국가명으로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(row):\n",
    "    if row['Country_Region'] in json_data:\n",
    "        row['Country_Region'] = json_data[row['Country_Region']]\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Confirmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anhui</td>\n",
       "      <td>China</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>China</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chongqing</td>\n",
       "      <td>China</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fujian</td>\n",
       "      <td>China</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Guangdong</td>\n",
       "      <td>China</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province_State Country_Region  Confirmed\n",
       "0          Anhui          China          1\n",
       "1        Beijing          China         14\n",
       "2      Chongqing          China          6\n",
       "3         Fujian          China          1\n",
       "5      Guangdong          China         26"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = doc.apply(func, axis=1)\n",
    "doc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 참고: 파일명으로 데이터 변환하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- lstrip(): 앞에(왼쪽에)서 특정 데이터 삭제하기, rstrip(): 뒤에(오른쪽에)서 특정 데이터 삭제하기\n",
    "- replace(변경전데이터, 변경후데이터): 문자열에서 변경전데이터 를 변경후데이터 로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1/22/2020'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = \"01-22-2020.csv\"\n",
    "date_column = data.split(\".\")[0].lstrip('0').replace('-', '/')\n",
    "date_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1/22/2020'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = \"01-22-2020.csv\"\n",
    "data.split('.')[0].lstrip(\"0\").replace('-', '/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Province_State', 'Country_Region', 'Confirmed'], dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Province_State', 'Country_Region', '1/22/2020'], dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.columns = ['Province_State', 'Country_Region', date_column]\n",
    "doc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>1/22/2020</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anhui</td>\n",
       "      <td>China</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>China</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chongqing</td>\n",
       "      <td>China</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fujian</td>\n",
       "      <td>China</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Guangdong</td>\n",
       "      <td>China</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province_State Country_Region  1/22/2020\n",
       "0          Anhui          China          1\n",
       "1        Beijing          China         14\n",
       "2      Chongqing          China          6\n",
       "3         Fujian          China          1\n",
       "5      Guangdong          China         26"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 중복 데이터 합치기\n",
    "- groupby() : 그룹별로 데이터를 집계하는 함수\n",
    "  - 동일한 컬럼값으로 묶어서 통계 또는 평균등을 확인할 수 있음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>성별</th>\n",
       "      <th>이름</th>\n",
       "      <th>수학</th>\n",
       "      <th>국어</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>남</td>\n",
       "      <td>David</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>남</td>\n",
       "      <td>Dave</td>\n",
       "      <td>50</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>남</td>\n",
       "      <td>Dave</td>\n",
       "      <td>80</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  성별     이름   수학  국어\n",
       "0  남  David  100  80\n",
       "1  남   Dave   50  70\n",
       "2  남   Dave   80  50"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    '성별': ['남', '남', '남'],\n",
    "    '이름': ['David', 'Dave', 'Dave'],\n",
    "    '수학': [100, 50, 80],\n",
    "    '국어': [80, 70, 50]    \n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>수학</th>\n",
       "      <th>국어</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>이름</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dave</th>\n",
       "      <td>65.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>David</th>\n",
       "      <td>100.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          수학    국어\n",
       "이름                \n",
       "Dave    65.0  60.0\n",
       "David  100.0  80.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.groupby('이름').mean() 메서드는 숫자 컬럼에 대해서만 계산 가능합니다.\n",
    "# 기존에는 df.groupby('이름').mean() 호출시, 숫자 컬럼 외에는 자동 제외하고 계산하였으나, 최근 버전에서는 자동 제외되지 않으므로,\n",
    "# 다음과 같이 숫자 컬럼만을 강제로 선택한 후, df.groupby('이름').mean() 을 호출하면 좋을 것 같습니다.\n",
    "selected_columns = ['이름', '수학', '국어']\n",
    "df = df[selected_columns]\n",
    "\n",
    "df.groupby('이름').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>수학</th>\n",
       "      <th>국어</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>이름</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dave</th>\n",
       "      <td>130</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>David</th>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        수학   국어\n",
       "이름             \n",
       "Dave   130  120\n",
       "David  100   80"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('이름').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 국가별 총 확진자수 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Confirmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anhui</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chongqing</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fujian</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Guangdong</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province_State  Country_Region  Confirmed\n",
       "0          Anhui  Mainland China          1\n",
       "1        Beijing  Mainland China         14\n",
       "2      Chongqing  Mainland China          6\n",
       "3         Fujian  Mainland China          1\n",
       "5      Guangdong  Mainland China         26"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "doc = pd.read_csv(PATH + \"01-22-2020.csv\", encoding='utf-8-sig')\n",
    "try:\n",
    "    doc = doc[['Province_State', 'Country_Region', 'Confirmed']]  # 1. 특정 컬럼만 선택해서 데이터프레임 만들기\n",
    "except:\n",
    "    doc = doc[['Province/State', 'Country/Region', 'Confirmed']]  # 1. 특정 컬럼만 선택해서 데이터프레임 만들기\n",
    "    doc.columns = ['Province_State', 'Country_Region', 'Confirmed']\n",
    "doc = doc.dropna(subset=['Confirmed'])     # 2. 특정 컬럼에 없는 데이터 삭제하기\n",
    "doc = doc.astype({'Confirmed': 'int64'})   # 3. 특정 컬럼의 데이터 타입 변경하기\n",
    "doc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Confirmed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country_Region</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Antarctica</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Japan</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kiribati</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Korea, North</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Macau</th>\n",
       "      <td>Macau</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mainland China</th>\n",
       "      <td>AnhuiBeijingChongqingFujianGuangdongGuangxiGui...</td>\n",
       "      <td>547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Malaysia</th>\n",
       "      <td>JohorKedahKelantanMelakaNegeri SembilanPahangP...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nauru</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Zealand</th>\n",
       "      <td>Cook IslandsNiue</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Palau</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Korea</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Summer Olympics 2020</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Taiwan</th>\n",
       "      <td>Taiwan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thailand</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tonga</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tuvalu</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US</th>\n",
       "      <td>Washington</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ukraine</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United Kingdom</th>\n",
       "      <td>JerseyGuernseyEnglandNorthern IrelandScotlandW...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Winter Olympics 2022</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         Province_State  \\\n",
       "Country_Region                                                            \n",
       "Antarctica                                                            0   \n",
       "Japan                                                                 0   \n",
       "Kiribati                                                              0   \n",
       "Korea, North                                                          0   \n",
       "Macau                                                             Macau   \n",
       "Mainland China        AnhuiBeijingChongqingFujianGuangdongGuangxiGui...   \n",
       "Malaysia              JohorKedahKelantanMelakaNegeri SembilanPahangP...   \n",
       "Nauru                                                                 0   \n",
       "New Zealand                                            Cook IslandsNiue   \n",
       "Palau                                                                 0   \n",
       "South Korea                                                           0   \n",
       "Summer Olympics 2020                                                  0   \n",
       "Taiwan                                                           Taiwan   \n",
       "Thailand                                                              0   \n",
       "Tonga                                                                 0   \n",
       "Tuvalu                                                                0   \n",
       "US                                                           Washington   \n",
       "Ukraine                                                         Unknown   \n",
       "United Kingdom        JerseyGuernseyEnglandNorthern IrelandScotlandW...   \n",
       "Winter Olympics 2022                                                  0   \n",
       "\n",
       "                      Confirmed  \n",
       "Country_Region                   \n",
       "Antarctica                    0  \n",
       "Japan                         2  \n",
       "Kiribati                      0  \n",
       "Korea, North                  0  \n",
       "Macau                         1  \n",
       "Mainland China              547  \n",
       "Malaysia                      0  \n",
       "Nauru                         0  \n",
       "New Zealand                   0  \n",
       "Palau                         0  \n",
       "South Korea                   1  \n",
       "Summer Olympics 2020          0  \n",
       "Taiwan                        1  \n",
       "Thailand                      4  \n",
       "Tonga                         0  \n",
       "Tuvalu                        0  \n",
       "US                            1  \n",
       "Ukraine                       0  \n",
       "United Kingdom                0  \n",
       "Winter Olympics 2022          0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.groupby('Country_Region').sum()  # 4. Country_Region 컬럼값이 동일한 케이스를 그룹화해서, 각 그룹별 합계 확인하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 데이터 전처리하기\n",
    "- 지금까지의 과정을 모두 한데 모아서, 함수로 만들기\n",
    "  1. csv 파일 읽기\n",
    "  2. 'Country_Region', 'Confirmed' 두 개의 컬럼만 가져오기\n",
    "  3. 'Confirmed' 에 데이터가 없는 행 삭제하기\n",
    "  4. 'Country_Region'의 국가명을 여러 파일에 일관되게 변경하기\n",
    "  5. 'Confirmed' 데이터 타입을 int64(정수) 로 변경\n",
    "  6. 'Country_Region' 를 기준으로 중복된 데이터를 합치기\n",
    "  7. 파일명을 기반으로 날짜 문자열 변환하고, 'Confirmed' 컬럼명 변경하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('COVID-19-master/csse_covid_19_data/country_convert.json', 'r', encoding='utf-8-sig') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "\n",
    "def country_name_convert(row):\n",
    "    if row['Country_Region'] in json_data:\n",
    "        return json_data[row['Country_Region']]\n",
    "    return row['Country_Region']\n",
    "\n",
    "def create_dateframe(filename):\n",
    "\n",
    "    doc = pd.read_csv(PATH + filename, encoding='utf-8-sig')  # 1. csv 파일 읽기\n",
    "    try:\n",
    "        doc = doc[['Country_Region', 'Confirmed']]  # 2. 특정 컬럼만 선택해서 데이터프레임 만들기\n",
    "    except:\n",
    "        doc = doc[['Country/Region', 'Confirmed']]  # 2. 특정 컬럼만 선택해서 데이터프레임 만들기\n",
    "        doc.columns = ['Country_Region', 'Confirmed']\n",
    "    doc = doc.dropna(subset=['Confirmed'])     # 3. 특정 컬럼에 없는 데이터 삭제하기\n",
    "    doc['Country_Region'] = doc.apply(country_name_convert, axis=1)   # 4. 'Country_Region'의 국가명을 여러 파일에 일관되게 변경하기\n",
    "    doc = doc.astype({'Confirmed': 'int64'})   # 5. 특정 컬럼의 데이터 타입 변경하기\n",
    "    doc = doc.groupby('Country_Region').sum()  # 6. 특정 컬럼으로 중복된 데이터를 합치기\n",
    "\n",
    "    # 7. 파일명을 기반으로 날짜 문자열 변환하고, 'Confirmed' 컬럼명 변경하기\n",
    "    date_column = filename.split(\".\")[0].lstrip('0').replace('-', '/') \n",
    "    doc.columns = [date_column]\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Mainland China': 'China',\n",
       " 'Macau': 'China',\n",
       " 'South Korea': 'Korea, South',\n",
       " 'Aruba': 'Netherlands',\n",
       " ' Azerbaijan': 'Azerbaijan',\n",
       " 'Bahamas, The': 'Bahamas',\n",
       " 'Cape Verde': 'Cabo Verde',\n",
       " 'Cayman Islands': 'United Kingdom',\n",
       " 'Channel Islands': 'United Kingdom',\n",
       " 'Curacao': 'Netherlands',\n",
       " 'Czech Republic': 'Czechia',\n",
       " 'East Timor': 'Timor-Leste',\n",
       " 'Faroe Islands': 'Denmark',\n",
       " 'French Guiana': 'France',\n",
       " 'Gambia, The': 'Gambia',\n",
       " 'Gibraltar': 'United Kingdom',\n",
       " 'Greenland': 'Denmark',\n",
       " 'Guadeloupe': 'France',\n",
       " 'Guam': 'US',\n",
       " 'Guernsey': 'US',\n",
       " 'Hong Kong': 'China',\n",
       " 'Hong Kong SAR': 'China',\n",
       " 'Iran (Islamic Republic of)': 'Iran',\n",
       " 'Ivory Coast': \"Cote d'Ivoire\",\n",
       " 'Jersey': 'US',\n",
       " 'Macao SAR': 'China',\n",
       " 'Martinique': 'France',\n",
       " 'Mayotte': 'France',\n",
       " 'North Ireland': 'United Kingdom',\n",
       " 'Palestine': 'West Bank and Gaza',\n",
       " 'Puerto Rico': 'US',\n",
       " 'Republic of Ireland': 'Ireland',\n",
       " 'Republic of Korea': 'Korea, South',\n",
       " 'Republic of Moldova': 'Moldova',\n",
       " 'Republic of the Congo': 'Congo (Brazzaville)',\n",
       " 'Reunion': 'France',\n",
       " 'Russian Federation': 'Russia',\n",
       " 'Saint Barthelemy': 'France',\n",
       " 'Saint Martin': 'France',\n",
       " 'St. Martin': 'US',\n",
       " 'Taipei and environs': 'Taiwan',\n",
       " 'The Bahamas': 'Bahamas',\n",
       " 'The Gambia': 'Gambia',\n",
       " 'UK': 'United Kingdom',\n",
       " 'Vatican City': 'Holy See',\n",
       " 'Viet Nam': 'Vietnam',\n",
       " 'occupied Palestinian territory': 'West Bank and Gaza',\n",
       " 'Taiwan*': 'Taiwan',\n",
       " 'Malawi': 'France',\n",
       " 'South Sudan': 'Sudan',\n",
       " 'Western Sahara': 'Morocco',\n",
       " 'Namibia': 'Namibia'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테스트해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = create_dateframe(\"01-22-2020.csv\")\n",
    "doc2 = create_dateframe(\"04-01-2020.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4/01/2020</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country_Region</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Afghanistan</th>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albania</th>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algeria</th>\n",
       "      <td>847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Andorra</th>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Angola</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                4/01/2020\n",
       "Country_Region           \n",
       "Afghanistan           192\n",
       "Albania               259\n",
       "Algeria               847\n",
       "Andorra               390\n",
       "Angola                  8"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터프레임 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1/22/2020</th>\n",
       "      <th>4/01/2020</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country_Region</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Afghanistan</th>\n",
       "      <td>NaN</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albania</th>\n",
       "      <td>NaN</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algeria</th>\n",
       "      <td>NaN</td>\n",
       "      <td>847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Andorra</th>\n",
       "      <td>NaN</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Angola</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                1/22/2020  4/01/2020\n",
       "Country_Region                      \n",
       "Afghanistan           NaN        192\n",
       "Albania               NaN        259\n",
       "Algeria               NaN        847\n",
       "Andorra               NaN        390\n",
       "Angola                NaN          8"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = pd.merge(doc1, doc2, how='outer', left_index=True, right_index=True)\n",
    "doc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 없는 데이터는 0으로 값 대체하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1/22/2020</th>\n",
       "      <th>4/01/2020</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country_Region</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Afghanistan</th>\n",
       "      <td>0.0</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albania</th>\n",
       "      <td>0.0</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algeria</th>\n",
       "      <td>0.0</td>\n",
       "      <td>847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Andorra</th>\n",
       "      <td>0.0</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Angola</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vietnam</th>\n",
       "      <td>0.0</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West Bank and Gaza</th>\n",
       "      <td>0.0</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Winter Olympics 2022</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zambia</th>\n",
       "      <td>0.0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zimbabwe</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>190 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      1/22/2020  4/01/2020\n",
       "Country_Region                            \n",
       "Afghanistan                 0.0        192\n",
       "Albania                     0.0        259\n",
       "Algeria                     0.0        847\n",
       "Andorra                     0.0        390\n",
       "Angola                      0.0          8\n",
       "...                         ...        ...\n",
       "Vietnam                     0.0        218\n",
       "West Bank and Gaza          0.0        134\n",
       "Winter Olympics 2022        0.0          0\n",
       "Zambia                      0.0         36\n",
       "Zimbabwe                    0.0          8\n",
       "\n",
       "[190 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = doc.fillna(0)\n",
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고: 특정 폴더 파일 리스트 확인하기\n",
    "- split() 함수를 사용해서 특정 확장자를 가진 파일 리스트만 추출 가능\n",
    "- 문자열변수.split('.') 은 ['파일명', '확장자'] 와 같은 리스트가 반환되므로, 문자열변수.split('.')[-1] 을 통해, 이 중에서 마지막 아이템을 선택하면 됨\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['01-21-2022.csv', '02-26-2020.csv', '01-20-2022.csv', '02-27-2020.csv', '07-04-2021.csv', '07-05-2021.csv', '02-12-2022.csv', '02-13-2022.csv', '12-31-2021.csv', '12-30-2021.csv', '11-02-2021.csv', '11-03-2021.csv', '08-21-2021.csv', '08-20-2021.csv', '11-09-2022.csv', '11-08-2022.csv', '03-25-2021.csv', '03-24-2021.csv', '06-07-2020.csv', '06-06-2020.csv', '05-01-2022.csv', '02-19-2021.csv', '10-01-2020.csv', '02-18-2021.csv', '09-22-2020.csv', '09-23-2020.csv', '04-08-2020.csv', '09-16-2022.csv', '09-17-2022.csv', '04-09-2020.csv', '04-09-2021.csv', '04-08-2021.csv', '09-23-2021.csv', '09-22-2021.csv', '02-18-2020.csv', '02-19-2020.csv', '10-01-2021.csv', '06-06-2021.csv', '06-07-2021.csv', '03-24-2020.csv', '03-25-2020.csv', '03-10-2022.csv', '03-11-2022.csv', '08-20-2020.csv', '08-21-2020.csv', '12-04-2022.csv', '11-03-2020.csv', '12-05-2022.csv', '11-02-2020.csv', '08-14-2022.csv', '08-15-2022.csv', '12-30-2020.csv', '12-31-2020.csv', '07-31-2022.csv', '09-28-2022.csv', '09-29-2022.csv', '07-30-2022.csv', '02-13-2023.csv', '01-14-2021.csv', '02-12-2023.csv', '01-15-2021.csv', '07-05-2020.csv', '04-02-2022.csv', '07-04-2020.csv', '04-03-2022.csv', '02-27-2021.csv', '01-20-2023.csv', '02-26-2021.csv', '01-21-2023.csv', '01-20-2021.csv', '02-27-2023.csv', '01-21-2021.csv', '02-26-2023.csv', '04-02-2020.csv', '07-05-2022.csv', '04-03-2020.csv', '07-04-2022.csv', '01-14-2023.csv', '02-13-2021.csv', '01-15-2023.csv', '02-12-2021.csv', '09-28-2020.csv', '07-31-2020.csv', '07-30-2020.csv', '09-29-2020.csv', '12-30-2022.csv', '12-31-2022.csv', '08-14-2020.csv', '08-15-2020.csv', '11-03-2022.csv', '12-04-2020.csv', '11-02-2022.csv', '12-05-2020.csv', '08-20-2022.csv', '08-21-2022.csv', '11-08-2021.csv', '03-10-2020.csv', '11-09-2021.csv', '03-11-2020.csv', '03-24-2022.csv', '03-25-2022.csv', '05-01-2021.csv', '02-18-2022.csv', '02-19-2022.csv', '09-17-2021.csv', '09-16-2021.csv', '09-16-2020.csv', '04-08-2022.csv', '04-09-2022.csv', '09-17-2020.csv', '09-22-2022.csv', '09-23-2022.csv', '10-01-2022.csv', '02-19-2023.csv', '02-18-2023.csv', '06-07-2022.csv', '05-01-2020.csv', '06-06-2022.csv', '11-09-2020.csv', '03-11-2021.csv', '11-08-2020.csv', '03-10-2021.csv', '12-05-2021.csv', '12-04-2021.csv', '08-15-2021.csv', '08-14-2021.csv', '09-29-2021.csv', '07-30-2021.csv', '07-31-2021.csv', '09-28-2021.csv', '02-12-2020.csv', '01-15-2022.csv', '02-13-2020.csv', '01-14-2022.csv', '04-03-2021.csv', '04-02-2021.csv', '02-26-2022.csv', '02-27-2022.csv', '01-09-2023.csv', '10-16-2020.csv', '01-08-2023.csv', '10-17-2020.csv', '07-18-2022.csv', '09-01-2022.csv', '07-19-2022.csv', '10-22-2022.csv', '10-23-2022.csv', '05-23-2020.csv', '06-24-2022.csv', '05-22-2020.csv', '06-25-2022.csv', '03-06-2023.csv', '12-19-2020.csv', '03-07-2023.csv', '12-18-2020.csv', '08-09-2020.csv', '05-17-2022.csv', '06-10-2020.csv', '05-16-2022.csv', '06-11-2020.csv', '08-08-2020.csv', '12-26-2021.csv', '12-27-2021.csv', '11-15-2021.csv', '11-14-2021.csv', '07-13-2021.csv', '07-12-2021.csv', '10-29-2021.csv', '10-28-2021.csv', '04-20-2021.csv', '04-21-2021.csv', '02-05-2022.csv', '02-04-2022.csv', '01-03-2021.csv', '02-04-2023.csv', '01-02-2021.csv', '02-05-2023.csv', '04-21-2020.csv', '07-26-2022.csv', '04-20-2020.csv', '07-27-2022.csv', '10-28-2020.csv', '10-29-2020.csv', '04-15-2022.csv', '07-12-2020.csv', '04-14-2022.csv', '07-13-2020.csv', '11-14-2020.csv', '12-13-2022.csv', '11-15-2020.csv', '12-12-2022.csv', '05-29-2022.csv', '05-28-2022.csv', '11-20-2022.csv', '12-27-2020.csv', '11-21-2022.csv', '12-26-2020.csv', '08-03-2022.csv', '08-02-2022.csv', '08-08-2021.csv', '06-11-2021.csv', '06-10-2021.csv', '08-09-2021.csv', '03-07-2022.csv', '12-18-2021.csv', '03-06-2022.csv', '12-19-2021.csv', '05-22-2021.csv', '05-23-2021.csv', '01-08-2022.csv', '10-17-2021.csv', '01-09-2022.csv', '10-16-2021.csv', '07-19-2021.csv', '07-18-2021.csv', '09-01-2021.csv', '10-23-2021.csv', '10-22-2021.csv', '06-25-2021.csv', '06-24-2021.csv', '03-07-2020.csv', '03-06-2020.csv', '05-16-2021.csv', '05-17-2021.csv', '08-03-2020.csv', '08-02-2020.csv', '12-27-2022.csv', '11-20-2020.csv', '12-26-2022.csv', '11-21-2020.csv', '05-29-2020.csv', '05-28-2020.csv', '12-13-2020.csv', '11-14-2022.csv', '12-12-2020.csv', '11-15-2022.csv', '07-12-2022.csv', '04-15-2020.csv', '07-13-2022.csv', '04-14-2020.csv', '10-28-2022.csv', '10-29-2022.csv', '07-26-2020.csv', '04-21-2022.csv', '07-27-2020.csv', '04-20-2022.csv', '02-04-2021.csv', '01-03-2023.csv', '02-05-2021.csv', '01-02-2023.csv', '01-02-2022.csv', '02-05-2020.csv', '01-03-2022.csv', '02-04-2020.csv', '07-27-2021.csv', '07-26-2021.csv', '04-14-2021.csv', '04-15-2021.csv', '12-12-2021.csv', '12-13-2021.csv', '05-28-2021.csv', '05-29-2021.csv', '11-21-2021.csv', '11-20-2021.csv', '08-02-2021.csv', '08-03-2021.csv', '06-10-2022.csv', '05-17-2020.csv', '08-09-2022.csv', '08-08-2022.csv', '06-11-2022.csv', '05-16-2020.csv', '12-19-2022.csv', '03-06-2021.csv', '12-18-2022.csv', '03-07-2021.csv', '06-24-2020.csv', '05-23-2022.csv', '06-25-2020.csv', '05-22-2022.csv', '10-22-2020.csv', '10-23-2020.csv', '09-01-2020.csv', '07-18-2020.csv', '07-19-2020.csv', '10-16-2022.csv', '01-09-2021.csv', '10-17-2022.csv', '01-08-2021.csv', '06-23-2022.csv', '05-24-2020.csv', '06-22-2022.csv', '05-25-2020.csv', '03-01-2023.csv', '11-19-2022.csv', '11-18-2022.csv', '06-17-2020.csv', '05-10-2022.csv', '06-16-2020.csv', '05-11-2022.csv', '02-09-2021.csv', '10-11-2020.csv', '02-08-2021.csv', '10-10-2020.csv', '09-06-2022.csv', '04-18-2020.csv', '04-19-2020.csv', '09-07-2022.csv', '10-25-2022.csv', '10-24-2022.csv', '07-14-2021.csv', '07-15-2021.csv', '01-31-2022.csv', '01-30-2022.csv', '04-27-2021.csv', '04-26-2021.csv', '02-02-2022.csv', '02-03-2022.csv', '12-21-2021.csv', '12-20-2021.csv', '06-28-2021.csv', '08-31-2021.csv', '08-30-2021.csv', '06-29-2021.csv', '11-12-2021.csv', '11-13-2021.csv', '12-14-2022.csv', '11-13-2020.csv', '12-15-2022.csv', '11-12-2020.csv', '06-29-2020.csv', '08-30-2020.csv', '08-31-2020.csv', '06-28-2020.csv', '12-20-2020.csv', '11-27-2022.csv', '12-21-2020.csv', '11-26-2022.csv', '08-04-2022.csv', '08-05-2022.csv', '02-03-2023.csv', '01-04-2021.csv', '02-02-2023.csv', '01-05-2021.csv', '07-21-2022.csv', '04-26-2020.csv', '07-20-2022.csv', '04-27-2020.csv', '01-30-2023.csv', '01-31-2023.csv', '07-15-2020.csv', '04-12-2022.csv', '07-14-2020.csv', '04-13-2022.csv', '04-19-2021.csv', '04-18-2021.csv', '02-08-2020.csv', '10-10-2021.csv', '02-09-2020.csv', '10-11-2021.csv', '06-16-2021.csv', '06-17-2021.csv', '03-01-2022.csv', '05-25-2021.csv', '05-24-2021.csv', '06-22-2021.csv', '06-23-2021.csv', '11-18-2021.csv', '11-19-2021.csv', '03-01-2020.csv', '05-11-2021.csv', '05-10-2021.csv', '02-08-2022.csv', '02-09-2022.csv', '09-07-2021.csv', '09-06-2021.csv', '10-24-2021.csv', '10-25-2021.csv', '04-12-2020.csv', '07-15-2022.csv', '04-13-2020.csv', '07-14-2022.csv', '01-30-2021.csv', '01-31-2021.csv', '04-26-2022.csv', '07-21-2020.csv', '04-27-2022.csv', '07-20-2020.csv', '01-04-2023.csv', '02-03-2021.csv', '01-05-2023.csv', '02-02-2021.csv', '08-04-2020.csv', '08-05-2020.csv', '11-27-2020.csv', '12-20-2022.csv', '11-26-2020.csv', '12-21-2022.csv', '08-30-2022.csv', '06-29-2022.csv', '06-28-2022.csv', '08-31-2022.csv', '11-13-2022.csv', '12-14-2020.csv', '11-12-2022.csv', '12-15-2020.csv', '12-15-2021.csv', '12-14-2021.csv', '11-26-2021.csv', '11-27-2021.csv', '08-05-2021.csv', '08-04-2021.csv', '02-02-2020.csv', '01-05-2022.csv', '02-03-2020.csv', '01-04-2022.csv', '07-20-2021.csv', '07-21-2021.csv', '01-31-2020.csv', '01-30-2020.csv', '04-13-2021.csv', '04-12-2021.csv', '10-25-2020.csv', '10-24-2020.csv', '04-18-2022.csv', '09-06-2020.csv', '09-07-2020.csv', '04-19-2022.csv', '10-11-2022.csv', '02-09-2023.csv', '10-10-2022.csv', '02-08-2023.csv', '05-10-2020.csv', '06-17-2022.csv', '05-11-2020.csv', '06-16-2022.csv', '11-19-2020.csv', '03-01-2021.csv', '11-18-2020.csv', '05-24-2022.csv', '06-23-2020.csv', '05-25-2022.csv', '06-22-2020.csv', '03-29-2022.csv', '03-28-2022.csv', '11-05-2021.csv', '11-04-2021.csv', '08-26-2021.csv', '08-27-2021.csv', '02-21-2020.csv', '01-26-2022.csv', '02-20-2020.csv', '01-27-2022.csv', '07-03-2021.csv', '07-02-2021.csv', '02-15-2022.csv', '02-14-2022.csv', '04-30-2021.csv', '01-19-2023.csv', '10-06-2020.csv', '01-18-2023.csv', '10-07-2020.csv', '09-25-2020.csv', '09-24-2020.csv', '09-11-2022.csv', '07-08-2022.csv', '07-09-2022.csv', '09-10-2022.csv', '12-09-2020.csv', '12-08-2020.csv', '03-22-2021.csv', '03-23-2021.csv', '05-07-2022.csv', '08-19-2020.csv', '08-18-2020.csv', '05-06-2022.csv', '06-01-2020.csv', '06-01-2021.csv', '08-18-2021.csv', '08-19-2021.csv', '03-23-2020.csv', '03-22-2020.csv', '03-17-2022.csv', '12-08-2021.csv', '03-16-2022.csv', '12-09-2021.csv', '09-24-2021.csv', '09-25-2021.csv', '01-18-2022.csv', '10-07-2021.csv', '01-19-2022.csv', '10-06-2021.csv', '04-30-2020.csv', '01-13-2021.csv', '02-14-2023.csv', '01-12-2021.csv', '02-15-2023.csv', '04-05-2022.csv', '07-02-2020.csv', '04-04-2022.csv', '07-03-2020.csv', '01-27-2023.csv', '02-20-2021.csv', '01-26-2023.csv', '02-21-2021.csv', '08-27-2020.csv', '08-26-2020.csv', '11-04-2020.csv', '12-03-2022.csv', '11-05-2020.csv', '12-02-2022.csv', '08-13-2022.csv', '08-12-2022.csv', '11-30-2022.csv', '11-30-2020.csv', '03-28-2021.csv', '03-29-2021.csv', '08-13-2020.csv', '08-12-2020.csv', '12-03-2020.csv', '11-04-2022.csv', '12-02-2020.csv', '11-05-2022.csv', '08-27-2022.csv', '08-26-2022.csv', '02-20-2023.csv', '01-27-2021.csv', '02-21-2023.csv', '01-26-2021.csv', '07-02-2022.csv', '04-05-2020.csv', '07-03-2022.csv', '04-04-2020.csv', '02-14-2021.csv', '01-13-2023.csv', '02-15-2021.csv', '01-12-2023.csv', '04-30-2022.csv', '07-09-2021.csv', '09-10-2021.csv', '09-11-2021.csv', '07-08-2021.csv', '03-17-2020.csv', '03-16-2020.csv', '03-23-2022.csv', '03-22-2022.csv', '05-06-2021.csv', '05-07-2021.csv', '08-19-2022.csv', '05-07-2020.csv', '06-01-2022.csv', '05-06-2020.csv', '08-18-2022.csv', '12-09-2022.csv', '03-16-2021.csv', '12-08-2022.csv', '03-17-2021.csv', '07-08-2020.csv', '09-11-2020.csv', '09-10-2020.csv', '07-09-2020.csv', '09-25-2022.csv', '09-24-2022.csv', '10-06-2022.csv', '01-19-2021.csv', '10-07-2022.csv', '01-18-2021.csv', '01-12-2022.csv', '02-15-2020.csv', '01-13-2022.csv', '02-14-2020.csv', '04-04-2021.csv', '04-05-2021.csv', '01-26-2020.csv', '02-21-2022.csv', '01-27-2020.csv', '02-20-2022.csv', '12-02-2021.csv', '12-03-2021.csv', '08-12-2021.csv', '08-13-2021.csv', '03-29-2020.csv', '11-30-2021.csv', '03-28-2020.csv', '09-03-2021.csv', '09-02-2021.csv', '10-20-2021.csv', '10-21-2021.csv', '04-29-2021.csv', '04-28-2021.csv', '05-15-2021.csv', '05-14-2021.csv', '03-30-2022.csv', '03-31-2022.csv', '06-26-2021.csv', '06-27-2021.csv', '03-04-2020.csv', '03-05-2020.csv', '12-10-2020.csv', '11-17-2022.csv', '12-11-2020.csv', '11-16-2022.csv', '06-19-2020.csv', '06-18-2020.csv', '08-01-2020.csv', '12-24-2022.csv', '11-23-2020.csv', '12-25-2022.csv', '11-22-2020.csv', '07-25-2020.csv', '04-22-2022.csv', '07-24-2020.csv', '04-23-2022.csv', '02-07-2021.csv', '02-06-2021.csv', '01-01-2023.csv', '07-11-2022.csv', '04-16-2020.csv', '09-08-2022.csv', '09-09-2022.csv', '07-10-2022.csv', '04-17-2020.csv', '04-17-2021.csv', '04-16-2021.csv', '01-01-2022.csv', '02-06-2020.csv', '02-07-2020.csv', '07-24-2021.csv', '07-25-2021.csv', '11-22-2021.csv', '11-23-2021.csv', '08-01-2021.csv', '06-18-2021.csv', '06-19-2021.csv', '12-11-2021.csv', '12-10-2021.csv', '03-05-2021.csv', '03-04-2021.csv', '06-27-2020.csv', '05-20-2022.csv', '06-26-2020.csv', '05-21-2022.csv', '11-29-2022.csv', '11-28-2022.csv', '06-13-2022.csv', '05-14-2020.csv', '06-12-2022.csv', '05-15-2020.csv', '10-15-2022.csv', '10-14-2022.csv', '04-28-2020.csv', '04-29-2020.csv', '10-21-2020.csv', '10-20-2020.csv', '09-02-2020.csv', '09-03-2020.csv', '09-02-2022.csv', '09-03-2022.csv', '10-21-2022.csv', '10-20-2022.csv', '04-28-2022.csv', '04-29-2022.csv', '10-15-2020.csv', '10-14-2020.csv', '05-14-2022.csv', '06-13-2020.csv', '05-15-2022.csv', '06-12-2020.csv', '03-31-2021.csv', '11-29-2020.csv', '03-30-2021.csv', '11-28-2020.csv', '05-20-2020.csv', '06-27-2022.csv', '05-21-2020.csv', '06-26-2022.csv', '03-05-2023.csv', '03-04-2023.csv', '11-16-2021.csv', '11-17-2021.csv', '12-25-2021.csv', '12-24-2021.csv', '04-23-2021.csv', '04-22-2021.csv', '02-06-2022.csv', '02-07-2022.csv', '09-09-2021.csv', '07-10-2021.csv', '07-11-2021.csv', '09-08-2021.csv', '09-08-2020.csv', '04-16-2022.csv', '07-11-2020.csv', '04-17-2022.csv', '07-10-2020.csv', '09-09-2020.csv', '02-07-2023.csv', '01-01-2021.csv', '02-06-2023.csv', '04-22-2020.csv', '07-25-2022.csv', '04-23-2020.csv', '07-24-2022.csv', '11-23-2022.csv', '12-24-2020.csv', '11-22-2022.csv', '12-25-2020.csv', '06-19-2022.csv', '08-01-2022.csv', '06-18-2022.csv', '11-17-2020.csv', '12-10-2022.csv', '11-16-2020.csv', '12-11-2022.csv', '03-04-2022.csv', '03-05-2022.csv', '05-21-2021.csv', '05-20-2021.csv', '03-30-2020.csv', '11-28-2021.csv', '03-31-2020.csv', '11-29-2021.csv', '06-12-2021.csv', '06-13-2021.csv', '10-14-2021.csv', '10-15-2021.csv', '10-08-2020.csv', '01-17-2023.csv', '02-10-2021.csv', '10-09-2020.csv', '01-16-2023.csv', '02-11-2021.csv', '01-23-2021.csv', '02-24-2023.csv', '01-22-2021.csv', '02-25-2023.csv', '04-01-2020.csv', '07-06-2022.csv', '07-07-2022.csv', '12-07-2020.csv', '11-01-2022.csv', '12-06-2020.csv', '08-23-2022.csv', '08-22-2022.csv', '08-17-2020.csv', '05-09-2022.csv', '05-08-2022.csv', '08-16-2020.csv', '03-27-2022.csv', '03-26-2022.csv', '05-02-2021.csv', '05-03-2021.csv', '03-13-2020.csv', '03-12-2020.csv', '08-28-2021.csv', '06-30-2021.csv', '08-29-2021.csv', '01-28-2022.csv', '01-29-2022.csv', '09-14-2021.csv', '09-15-2021.csv', '09-21-2022.csv', '09-20-2022.csv', '10-02-2022.csv', '10-03-2022.csv', '09-15-2020.csv', '09-14-2020.csv', '01-29-2023.csv', '01-28-2023.csv', '08-29-2020.csv', '06-30-2020.csv', '08-28-2020.csv', '03-12-2021.csv', '03-13-2021.csv', '05-03-2020.csv', '06-04-2022.csv', '05-02-2020.csv', '06-05-2022.csv', '08-16-2021.csv', '08-17-2021.csv', '12-06-2021.csv', '03-19-2022.csv', '12-07-2021.csv', '03-18-2022.csv', '04-01-2021.csv', '02-25-2022.csv', '01-22-2020.csv', '02-24-2022.csv', '01-23-2020.csv', '10-09-2021.csv', '02-11-2020.csv', '01-16-2022.csv', '10-08-2021.csv', '02-10-2020.csv', '01-17-2022.csv', '02-11-2022.csv', '02-10-2022.csv', '01-22-2022.csv', '02-25-2020.csv', '01-23-2022.csv', '02-24-2020.csv', '07-07-2021.csv', '07-06-2021.csv', '03-19-2020.csv', '11-01-2021.csv', '03-18-2020.csv', '08-22-2021.csv', '08-23-2021.csv', '05-08-2021.csv', '05-09-2021.csv', '03-26-2021.csv', '03-27-2021.csv', '06-04-2020.csv', '05-03-2022.csv', '06-05-2020.csv', '05-02-2022.csv', '06-30-2022.csv', '08-29-2022.csv', '08-28-2022.csv', '01-29-2021.csv', '01-28-2021.csv', '09-15-2022.csv', '09-14-2022.csv', '10-02-2020.csv', '10-03-2020.csv', '09-21-2020.csv', '09-20-2020.csv', '09-20-2021.csv', '09-21-2021.csv', '10-03-2021.csv', '10-02-2021.csv', '01-28-2020.csv', '01-29-2020.csv', '03-13-2022.csv', '03-12-2022.csv', '06-05-2021.csv', '06-04-2021.csv', '03-27-2020.csv', '03-26-2020.csv', '05-09-2020.csv', '08-17-2022.csv', '08-16-2022.csv', '05-08-2020.csv', '08-23-2020.csv', '08-22-2020.csv', '03-18-2021.csv', '12-07-2022.csv', '03-19-2021.csv', '12-06-2022.csv', '11-01-2020.csv', '07-06-2020.csv', '04-01-2022.csv', '07-07-2020.csv', '02-24-2021.csv', '01-23-2023.csv', '02-25-2021.csv', '01-22-2023.csv', '02-10-2023.csv', '01-17-2021.csv', '10-08-2022.csv', '02-11-2023.csv', '01-16-2021.csv', '10-09-2022.csv', '11-07-2022.csv', '12-01-2020.csv', '11-06-2022.csv', '08-24-2022.csv', '08-25-2022.csv', '06-09-2020.csv', '08-10-2020.csv', '08-11-2020.csv', '06-08-2020.csv', '02-17-2021.csv', '01-10-2023.csv', '02-16-2021.csv', '01-11-2023.csv', '02-23-2023.csv', '01-24-2021.csv', '02-22-2023.csv', '01-25-2021.csv', '09-18-2022.csv', '07-01-2022.csv', '04-06-2020.csv', '04-07-2020.csv', '09-19-2022.csv', '10-30-2021.csv', '02-28-2020.csv', '10-31-2021.csv', '02-29-2020.csv', '09-13-2021.csv', '09-12-2021.csv', '03-20-2022.csv', '03-21-2022.csv', '05-05-2021.csv', '05-04-2021.csv', '03-14-2020.csv', '03-15-2020.csv', '05-30-2022.csv', '05-31-2022.csv', '03-15-2021.csv', '03-14-2021.csv', '06-03-2022.csv', '05-04-2020.csv', '06-02-2022.csv', '05-05-2020.csv', '09-26-2022.csv', '09-27-2022.csv', '10-05-2022.csv', '10-04-2022.csv', '09-12-2020.csv', '09-13-2020.csv', '10-31-2020.csv', '10-30-2020.csv', '02-28-2021.csv', '04-07-2021.csv', '04-06-2021.csv', '01-25-2020.csv', '02-22-2022.csv', '01-24-2020.csv', '02-23-2022.csv', '01-11-2022.csv', '02-16-2020.csv', '01-10-2022.csv', '02-17-2020.csv', '06-08-2021.csv', '08-11-2021.csv', '08-10-2021.csv', '06-09-2021.csv', '12-01-2021.csv', '11-06-2021.csv', '11-07-2021.csv', '08-25-2021.csv', '08-24-2021.csv', '02-16-2022.csv', '02-17-2022.csv', '02-22-2020.csv', '01-25-2022.csv', '02-23-2020.csv', '01-24-2022.csv', '09-19-2021.csv', '09-18-2021.csv', '07-01-2021.csv', '10-31-2022.csv', '02-28-2023.csv', '10-30-2022.csv', '09-12-2022.csv', '09-13-2022.csv', '10-05-2020.csv', '10-04-2020.csv', '09-26-2020.csv', '09-27-2020.csv', '03-21-2021.csv', '03-20-2021.csv', '05-04-2022.csv', '06-03-2020.csv', '05-05-2022.csv', '06-02-2020.csv', '05-30-2020.csv', '05-31-2020.csv', '05-31-2021.csv', '05-30-2021.csv', '03-14-2022.csv', '03-15-2022.csv', '06-02-2021.csv', '06-03-2021.csv', '03-20-2020.csv', '03-21-2020.csv', '09-27-2021.csv', '09-26-2021.csv', '10-04-2021.csv', '10-05-2021.csv', '02-28-2022.csv', '04-06-2022.csv', '07-01-2020.csv', '09-18-2020.csv', '09-19-2020.csv', '04-07-2022.csv', '01-24-2023.csv', '02-23-2021.csv', '01-25-2023.csv', '02-22-2021.csv', '01-10-2021.csv', '02-17-2023.csv', '01-11-2021.csv', '02-16-2023.csv', '08-10-2022.csv', '06-09-2022.csv', '06-08-2022.csv', '08-11-2022.csv', '08-24-2020.csv', '08-25-2020.csv', '11-07-2020.csv', '11-06-2020.csv', '12-01-2022.csv', '05-12-2021.csv', '05-13-2021.csv', '12-28-2021.csv', '12-29-2021.csv', '06-21-2021.csv', '06-20-2021.csv', '03-03-2020.csv', '03-02-2020.csv', '09-04-2021.csv', '09-05-2021.csv', '10-27-2021.csv', '10-26-2021.csv', '04-25-2022.csv', '07-22-2020.csv', '04-24-2022.csv', '07-23-2020.csv', '10-18-2020.csv', '01-07-2023.csv', '10-19-2020.csv', '01-06-2023.csv', '02-01-2021.csv', '04-11-2020.csv', '07-16-2022.csv', '04-10-2020.csv', '07-17-2022.csv', '11-10-2022.csv', '12-17-2020.csv', '03-08-2023.csv', '11-11-2022.csv', '12-16-2020.csv', '03-09-2023.csv', '05-19-2022.csv', '08-07-2020.csv', '08-06-2020.csv', '05-18-2022.csv', '11-24-2020.csv', '12-23-2022.csv', '11-25-2020.csv', '12-22-2022.csv', '11-25-2021.csv', '11-24-2021.csv', '08-06-2021.csv', '08-07-2021.csv', '12-16-2021.csv', '03-09-2022.csv', '12-17-2021.csv', '03-08-2022.csv', '04-10-2021.csv', '04-11-2021.csv', '10-19-2021.csv', '02-01-2020.csv', '01-06-2022.csv', '10-18-2021.csv', '01-07-2022.csv', '07-23-2021.csv', '07-22-2021.csv', '10-12-2022.csv', '10-13-2022.csv', '07-28-2022.csv', '07-29-2022.csv', '09-30-2022.csv', '10-26-2020.csv', '10-27-2020.csv', '09-05-2020.csv', '09-04-2020.csv', '03-02-2021.csv', '03-03-2021.csv', '05-27-2022.csv', '06-20-2020.csv', '05-26-2022.csv', '06-21-2020.csv', '12-29-2020.csv', '12-28-2020.csv', '05-13-2020.csv', '06-14-2022.csv', '05-12-2020.csv', '06-15-2022.csv', '06-14-2020.csv', '05-13-2022.csv', '06-15-2020.csv', '05-12-2022.csv', '12-29-2022.csv', '12-28-2022.csv', '06-20-2022.csv', '05-27-2020.csv', '06-21-2022.csv', '05-26-2020.csv', '03-02-2023.csv', '03-03-2023.csv', '09-05-2022.csv', '09-04-2022.csv', '10-26-2022.csv', '10-27-2022.csv', '07-28-2020.csv', '09-30-2020.csv', '07-29-2020.csv', '10-12-2020.csv', '10-13-2020.csv', '04-24-2021.csv', '04-25-2021.csv', '02-01-2022.csv', '07-17-2021.csv', '07-16-2021.csv', '03-09-2020.csv', '11-11-2021.csv', '03-08-2020.csv', '11-10-2021.csv', '05-18-2021.csv', '05-19-2021.csv', '12-22-2021.csv', '12-23-2021.csv', '12-23-2020.csv', '11-24-2022.csv', '12-22-2020.csv', '11-25-2022.csv', '08-07-2022.csv', '05-19-2020.csv', '05-18-2020.csv', '08-06-2022.csv', '03-08-2021.csv', '12-17-2022.csv', '11-10-2020.csv', '03-09-2021.csv', '12-16-2022.csv', '11-11-2020.csv', '07-16-2020.csv', '04-11-2022.csv', '07-17-2020.csv', '04-10-2022.csv', '01-07-2021.csv', '10-18-2022.csv', '02-01-2023.csv', '01-06-2021.csv', '10-19-2022.csv', '07-22-2022.csv', '04-25-2020.csv', '07-23-2022.csv', '04-24-2020.csv', '10-13-2021.csv', '10-12-2021.csv', '07-29-2021.csv', '09-30-2021.csv', '07-28-2021.csv', '03-03-2022.csv', '03-02-2022.csv', '05-26-2021.csv', '05-27-2021.csv', '06-15-2021.csv', '06-14-2021.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "PATH = 'COVID-19-master/csse_covid_19_data/csse_covid_19_daily_reports/'\n",
    "file_list = os.listdir(PATH)\n",
    "csv_list = list()\n",
    "\n",
    "for file in file_list:\n",
    "    if file.split(\".\")[-1] == 'csv':\n",
    "        csv_list.append(file)\n",
    "\n",
    "print (csv_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고: 리스트 정렬\n",
    "- 리스트변수.sort() : 오름차순 정렬 (디폴트)\n",
    "- 리스트변수.sort(reverse=True) : 내림차순 정렬\n",
    "- 리스트변수.sort(key=키함수) : 키 함수를 사용하여 정렬 기준 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01-22-2020.csv',\n",
       " '01-23-2020.csv',\n",
       " '01-24-2020.csv',\n",
       " '01-25-2020.csv',\n",
       " '01-26-2020.csv',\n",
       " '01-27-2020.csv',\n",
       " '01-28-2020.csv',\n",
       " '01-29-2020.csv',\n",
       " '01-30-2020.csv',\n",
       " '01-31-2020.csv',\n",
       " '02-01-2020.csv',\n",
       " '02-02-2020.csv',\n",
       " '02-03-2020.csv',\n",
       " '02-04-2020.csv',\n",
       " '02-05-2020.csv',\n",
       " '02-06-2020.csv',\n",
       " '02-07-2020.csv',\n",
       " '02-08-2020.csv',\n",
       " '02-09-2020.csv',\n",
       " '02-10-2020.csv',\n",
       " '02-11-2020.csv',\n",
       " '02-12-2020.csv',\n",
       " '02-13-2020.csv',\n",
       " '02-14-2020.csv',\n",
       " '02-15-2020.csv',\n",
       " '02-16-2020.csv',\n",
       " '02-17-2020.csv',\n",
       " '02-18-2020.csv',\n",
       " '02-19-2020.csv',\n",
       " '02-20-2020.csv',\n",
       " '02-21-2020.csv',\n",
       " '02-22-2020.csv',\n",
       " '02-23-2020.csv',\n",
       " '02-24-2020.csv',\n",
       " '02-25-2020.csv',\n",
       " '02-26-2020.csv',\n",
       " '02-27-2020.csv',\n",
       " '02-28-2020.csv',\n",
       " '02-29-2020.csv',\n",
       " '03-01-2020.csv',\n",
       " '03-02-2020.csv',\n",
       " '03-03-2020.csv',\n",
       " '03-04-2020.csv',\n",
       " '03-05-2020.csv',\n",
       " '03-06-2020.csv',\n",
       " '03-07-2020.csv',\n",
       " '03-08-2020.csv',\n",
       " '03-09-2020.csv',\n",
       " '03-10-2020.csv',\n",
       " '03-11-2020.csv',\n",
       " '03-12-2020.csv',\n",
       " '03-13-2020.csv',\n",
       " '03-14-2020.csv',\n",
       " '03-15-2020.csv',\n",
       " '03-16-2020.csv',\n",
       " '03-17-2020.csv',\n",
       " '03-18-2020.csv',\n",
       " '03-19-2020.csv',\n",
       " '03-20-2020.csv',\n",
       " '03-21-2020.csv',\n",
       " '03-22-2020.csv',\n",
       " '03-23-2020.csv',\n",
       " '03-24-2020.csv',\n",
       " '03-25-2020.csv',\n",
       " '03-26-2020.csv',\n",
       " '03-27-2020.csv',\n",
       " '03-28-2020.csv',\n",
       " '03-29-2020.csv',\n",
       " '03-30-2020.csv',\n",
       " '03-31-2020.csv',\n",
       " '04-01-2020.csv',\n",
       " '04-02-2020.csv',\n",
       " '04-03-2020.csv',\n",
       " '04-04-2020.csv',\n",
       " '04-05-2020.csv',\n",
       " '04-06-2020.csv',\n",
       " '04-07-2020.csv',\n",
       " '04-08-2020.csv',\n",
       " '04-09-2020.csv',\n",
       " '04-10-2020.csv',\n",
       " '04-11-2020.csv',\n",
       " '04-12-2020.csv',\n",
       " '04-13-2020.csv',\n",
       " '04-14-2020.csv',\n",
       " '04-15-2020.csv',\n",
       " '04-16-2020.csv',\n",
       " '04-17-2020.csv',\n",
       " '04-18-2020.csv',\n",
       " '04-19-2020.csv',\n",
       " '04-20-2020.csv',\n",
       " '04-21-2020.csv',\n",
       " '04-22-2020.csv',\n",
       " '04-23-2020.csv',\n",
       " '04-24-2020.csv',\n",
       " '04-25-2020.csv',\n",
       " '04-26-2020.csv',\n",
       " '04-27-2020.csv',\n",
       " '04-28-2020.csv',\n",
       " '04-29-2020.csv',\n",
       " '04-30-2020.csv',\n",
       " '05-01-2020.csv',\n",
       " '05-02-2020.csv',\n",
       " '05-03-2020.csv',\n",
       " '05-04-2020.csv',\n",
       " '05-05-2020.csv',\n",
       " '05-06-2020.csv',\n",
       " '05-07-2020.csv',\n",
       " '05-08-2020.csv',\n",
       " '05-09-2020.csv',\n",
       " '05-10-2020.csv',\n",
       " '05-11-2020.csv',\n",
       " '05-12-2020.csv',\n",
       " '05-13-2020.csv',\n",
       " '05-14-2020.csv',\n",
       " '05-15-2020.csv',\n",
       " '05-16-2020.csv',\n",
       " '05-17-2020.csv',\n",
       " '05-18-2020.csv',\n",
       " '05-19-2020.csv',\n",
       " '05-20-2020.csv',\n",
       " '05-21-2020.csv',\n",
       " '05-22-2020.csv',\n",
       " '05-23-2020.csv',\n",
       " '05-24-2020.csv',\n",
       " '05-25-2020.csv',\n",
       " '05-26-2020.csv',\n",
       " '05-27-2020.csv',\n",
       " '05-28-2020.csv',\n",
       " '05-29-2020.csv',\n",
       " '05-30-2020.csv',\n",
       " '05-31-2020.csv',\n",
       " '06-01-2020.csv',\n",
       " '06-02-2020.csv',\n",
       " '06-03-2020.csv',\n",
       " '06-04-2020.csv',\n",
       " '06-05-2020.csv',\n",
       " '06-06-2020.csv',\n",
       " '06-07-2020.csv',\n",
       " '06-08-2020.csv',\n",
       " '06-09-2020.csv',\n",
       " '06-10-2020.csv',\n",
       " '06-11-2020.csv',\n",
       " '06-12-2020.csv',\n",
       " '06-13-2020.csv',\n",
       " '06-14-2020.csv',\n",
       " '06-15-2020.csv',\n",
       " '06-16-2020.csv',\n",
       " '06-17-2020.csv',\n",
       " '06-18-2020.csv',\n",
       " '06-19-2020.csv',\n",
       " '06-20-2020.csv',\n",
       " '06-21-2020.csv',\n",
       " '06-22-2020.csv',\n",
       " '06-23-2020.csv',\n",
       " '06-24-2020.csv',\n",
       " '06-25-2020.csv',\n",
       " '06-26-2020.csv',\n",
       " '06-27-2020.csv',\n",
       " '06-28-2020.csv',\n",
       " '06-29-2020.csv',\n",
       " '06-30-2020.csv',\n",
       " '07-01-2020.csv',\n",
       " '07-02-2020.csv',\n",
       " '07-03-2020.csv',\n",
       " '07-04-2020.csv',\n",
       " '07-05-2020.csv',\n",
       " '07-06-2020.csv',\n",
       " '07-07-2020.csv',\n",
       " '07-08-2020.csv',\n",
       " '07-09-2020.csv',\n",
       " '07-10-2020.csv',\n",
       " '07-11-2020.csv',\n",
       " '07-12-2020.csv',\n",
       " '07-13-2020.csv',\n",
       " '07-14-2020.csv',\n",
       " '07-15-2020.csv',\n",
       " '07-16-2020.csv',\n",
       " '07-17-2020.csv',\n",
       " '07-18-2020.csv',\n",
       " '07-19-2020.csv',\n",
       " '07-20-2020.csv',\n",
       " '07-21-2020.csv',\n",
       " '07-22-2020.csv',\n",
       " '07-23-2020.csv',\n",
       " '07-24-2020.csv',\n",
       " '07-25-2020.csv',\n",
       " '07-26-2020.csv',\n",
       " '07-27-2020.csv',\n",
       " '07-28-2020.csv',\n",
       " '07-29-2020.csv',\n",
       " '07-30-2020.csv',\n",
       " '07-31-2020.csv',\n",
       " '08-01-2020.csv',\n",
       " '08-02-2020.csv',\n",
       " '08-03-2020.csv',\n",
       " '08-04-2020.csv',\n",
       " '08-05-2020.csv',\n",
       " '08-06-2020.csv',\n",
       " '08-07-2020.csv',\n",
       " '08-08-2020.csv',\n",
       " '08-09-2020.csv',\n",
       " '08-10-2020.csv',\n",
       " '08-11-2020.csv',\n",
       " '08-12-2020.csv',\n",
       " '08-13-2020.csv',\n",
       " '08-14-2020.csv',\n",
       " '08-15-2020.csv',\n",
       " '08-16-2020.csv',\n",
       " '08-17-2020.csv',\n",
       " '08-18-2020.csv',\n",
       " '08-19-2020.csv',\n",
       " '08-20-2020.csv',\n",
       " '08-21-2020.csv',\n",
       " '08-22-2020.csv',\n",
       " '08-23-2020.csv',\n",
       " '08-24-2020.csv',\n",
       " '08-25-2020.csv',\n",
       " '08-26-2020.csv',\n",
       " '08-27-2020.csv',\n",
       " '08-28-2020.csv',\n",
       " '08-29-2020.csv',\n",
       " '08-30-2020.csv',\n",
       " '08-31-2020.csv',\n",
       " '09-01-2020.csv',\n",
       " '09-02-2020.csv',\n",
       " '09-03-2020.csv',\n",
       " '09-04-2020.csv',\n",
       " '09-05-2020.csv',\n",
       " '09-06-2020.csv',\n",
       " '09-07-2020.csv',\n",
       " '09-08-2020.csv',\n",
       " '09-09-2020.csv',\n",
       " '09-10-2020.csv',\n",
       " '09-11-2020.csv',\n",
       " '09-12-2020.csv',\n",
       " '09-13-2020.csv',\n",
       " '09-14-2020.csv',\n",
       " '09-15-2020.csv',\n",
       " '09-16-2020.csv',\n",
       " '09-17-2020.csv',\n",
       " '09-18-2020.csv',\n",
       " '09-19-2020.csv',\n",
       " '09-20-2020.csv',\n",
       " '09-21-2020.csv',\n",
       " '09-22-2020.csv',\n",
       " '09-23-2020.csv',\n",
       " '09-24-2020.csv',\n",
       " '09-25-2020.csv',\n",
       " '09-26-2020.csv',\n",
       " '09-27-2020.csv',\n",
       " '09-28-2020.csv',\n",
       " '09-29-2020.csv',\n",
       " '09-30-2020.csv',\n",
       " '10-01-2020.csv',\n",
       " '10-02-2020.csv',\n",
       " '10-03-2020.csv',\n",
       " '10-04-2020.csv',\n",
       " '10-05-2020.csv',\n",
       " '10-06-2020.csv',\n",
       " '10-07-2020.csv',\n",
       " '10-08-2020.csv',\n",
       " '10-09-2020.csv',\n",
       " '10-10-2020.csv',\n",
       " '10-11-2020.csv',\n",
       " '10-12-2020.csv',\n",
       " '10-13-2020.csv',\n",
       " '10-14-2020.csv',\n",
       " '10-15-2020.csv',\n",
       " '10-16-2020.csv',\n",
       " '10-17-2020.csv',\n",
       " '10-18-2020.csv',\n",
       " '10-19-2020.csv',\n",
       " '10-20-2020.csv',\n",
       " '10-21-2020.csv',\n",
       " '10-22-2020.csv',\n",
       " '10-23-2020.csv',\n",
       " '10-24-2020.csv',\n",
       " '10-25-2020.csv',\n",
       " '10-26-2020.csv',\n",
       " '10-27-2020.csv',\n",
       " '10-28-2020.csv',\n",
       " '10-29-2020.csv',\n",
       " '10-30-2020.csv',\n",
       " '10-31-2020.csv',\n",
       " '11-01-2020.csv',\n",
       " '11-02-2020.csv',\n",
       " '11-03-2020.csv',\n",
       " '11-04-2020.csv',\n",
       " '11-05-2020.csv',\n",
       " '11-06-2020.csv',\n",
       " '11-07-2020.csv',\n",
       " '11-08-2020.csv',\n",
       " '11-09-2020.csv',\n",
       " '11-10-2020.csv',\n",
       " '11-11-2020.csv',\n",
       " '11-12-2020.csv',\n",
       " '11-13-2020.csv',\n",
       " '11-14-2020.csv',\n",
       " '11-15-2020.csv',\n",
       " '11-16-2020.csv',\n",
       " '11-17-2020.csv',\n",
       " '11-18-2020.csv',\n",
       " '11-19-2020.csv',\n",
       " '11-20-2020.csv',\n",
       " '11-21-2020.csv',\n",
       " '11-22-2020.csv',\n",
       " '11-23-2020.csv',\n",
       " '11-24-2020.csv',\n",
       " '11-25-2020.csv',\n",
       " '11-26-2020.csv',\n",
       " '11-27-2020.csv',\n",
       " '11-28-2020.csv',\n",
       " '11-29-2020.csv',\n",
       " '11-30-2020.csv',\n",
       " '12-01-2020.csv',\n",
       " '12-02-2020.csv',\n",
       " '12-03-2020.csv',\n",
       " '12-04-2020.csv',\n",
       " '12-05-2020.csv',\n",
       " '12-06-2020.csv',\n",
       " '12-07-2020.csv',\n",
       " '12-08-2020.csv',\n",
       " '12-09-2020.csv',\n",
       " '12-10-2020.csv',\n",
       " '12-11-2020.csv',\n",
       " '12-12-2020.csv',\n",
       " '12-13-2020.csv',\n",
       " '12-14-2020.csv',\n",
       " '12-15-2020.csv',\n",
       " '12-16-2020.csv',\n",
       " '12-17-2020.csv',\n",
       " '12-18-2020.csv',\n",
       " '12-19-2020.csv',\n",
       " '12-20-2020.csv',\n",
       " '12-21-2020.csv',\n",
       " '12-22-2020.csv',\n",
       " '12-23-2020.csv',\n",
       " '12-24-2020.csv',\n",
       " '12-25-2020.csv',\n",
       " '12-26-2020.csv',\n",
       " '12-27-2020.csv',\n",
       " '12-28-2020.csv',\n",
       " '12-29-2020.csv',\n",
       " '12-30-2020.csv',\n",
       " '12-31-2020.csv',\n",
       " '01-01-2021.csv',\n",
       " '01-02-2021.csv',\n",
       " '01-03-2021.csv',\n",
       " '01-04-2021.csv',\n",
       " '01-05-2021.csv',\n",
       " '01-06-2021.csv',\n",
       " '01-07-2021.csv',\n",
       " '01-08-2021.csv',\n",
       " '01-09-2021.csv',\n",
       " '01-10-2021.csv',\n",
       " '01-11-2021.csv',\n",
       " '01-12-2021.csv',\n",
       " '01-13-2021.csv',\n",
       " '01-14-2021.csv',\n",
       " '01-15-2021.csv',\n",
       " '01-16-2021.csv',\n",
       " '01-17-2021.csv',\n",
       " '01-18-2021.csv',\n",
       " '01-19-2021.csv',\n",
       " '01-20-2021.csv',\n",
       " '01-21-2021.csv',\n",
       " '01-22-2021.csv',\n",
       " '01-23-2021.csv',\n",
       " '01-24-2021.csv',\n",
       " '01-25-2021.csv',\n",
       " '01-26-2021.csv',\n",
       " '01-27-2021.csv',\n",
       " '01-28-2021.csv',\n",
       " '01-29-2021.csv',\n",
       " '01-30-2021.csv',\n",
       " '01-31-2021.csv',\n",
       " '02-01-2021.csv',\n",
       " '02-02-2021.csv',\n",
       " '02-03-2021.csv',\n",
       " '02-04-2021.csv',\n",
       " '02-05-2021.csv',\n",
       " '02-06-2021.csv',\n",
       " '02-07-2021.csv',\n",
       " '02-08-2021.csv',\n",
       " '02-09-2021.csv',\n",
       " '02-10-2021.csv',\n",
       " '02-11-2021.csv',\n",
       " '02-12-2021.csv',\n",
       " '02-13-2021.csv',\n",
       " '02-14-2021.csv',\n",
       " '02-15-2021.csv',\n",
       " '02-16-2021.csv',\n",
       " '02-17-2021.csv',\n",
       " '02-18-2021.csv',\n",
       " '02-19-2021.csv',\n",
       " '02-20-2021.csv',\n",
       " '02-21-2021.csv',\n",
       " '02-22-2021.csv',\n",
       " '02-23-2021.csv',\n",
       " '02-24-2021.csv',\n",
       " '02-25-2021.csv',\n",
       " '02-26-2021.csv',\n",
       " '02-27-2021.csv',\n",
       " '02-28-2021.csv',\n",
       " '03-01-2021.csv',\n",
       " '03-02-2021.csv',\n",
       " '03-03-2021.csv',\n",
       " '03-04-2021.csv',\n",
       " '03-05-2021.csv',\n",
       " '03-06-2021.csv',\n",
       " '03-07-2021.csv',\n",
       " '03-08-2021.csv',\n",
       " '03-09-2021.csv',\n",
       " '03-10-2021.csv',\n",
       " '03-11-2021.csv',\n",
       " '03-12-2021.csv',\n",
       " '03-13-2021.csv',\n",
       " '03-14-2021.csv',\n",
       " '03-15-2021.csv',\n",
       " '03-16-2021.csv',\n",
       " '03-17-2021.csv',\n",
       " '03-18-2021.csv',\n",
       " '03-19-2021.csv',\n",
       " '03-20-2021.csv',\n",
       " '03-21-2021.csv',\n",
       " '03-22-2021.csv',\n",
       " '03-23-2021.csv',\n",
       " '03-24-2021.csv',\n",
       " '03-25-2021.csv',\n",
       " '03-26-2021.csv',\n",
       " '03-27-2021.csv',\n",
       " '03-28-2021.csv',\n",
       " '03-29-2021.csv',\n",
       " '03-30-2021.csv',\n",
       " '03-31-2021.csv',\n",
       " '04-01-2021.csv',\n",
       " '04-02-2021.csv',\n",
       " '04-03-2021.csv',\n",
       " '04-04-2021.csv',\n",
       " '04-05-2021.csv',\n",
       " '04-06-2021.csv',\n",
       " '04-07-2021.csv',\n",
       " '04-08-2021.csv',\n",
       " '04-09-2021.csv',\n",
       " '04-10-2021.csv',\n",
       " '04-11-2021.csv',\n",
       " '04-12-2021.csv',\n",
       " '04-13-2021.csv',\n",
       " '04-14-2021.csv',\n",
       " '04-15-2021.csv',\n",
       " '04-16-2021.csv',\n",
       " '04-17-2021.csv',\n",
       " '04-18-2021.csv',\n",
       " '04-19-2021.csv',\n",
       " '04-20-2021.csv',\n",
       " '04-21-2021.csv',\n",
       " '04-22-2021.csv',\n",
       " '04-23-2021.csv',\n",
       " '04-24-2021.csv',\n",
       " '04-25-2021.csv',\n",
       " '04-26-2021.csv',\n",
       " '04-27-2021.csv',\n",
       " '04-28-2021.csv',\n",
       " '04-29-2021.csv',\n",
       " '04-30-2021.csv',\n",
       " '05-01-2021.csv',\n",
       " '05-02-2021.csv',\n",
       " '05-03-2021.csv',\n",
       " '05-04-2021.csv',\n",
       " '05-05-2021.csv',\n",
       " '05-06-2021.csv',\n",
       " '05-07-2021.csv',\n",
       " '05-08-2021.csv',\n",
       " '05-09-2021.csv',\n",
       " '05-10-2021.csv',\n",
       " '05-11-2021.csv',\n",
       " '05-12-2021.csv',\n",
       " '05-13-2021.csv',\n",
       " '05-14-2021.csv',\n",
       " '05-15-2021.csv',\n",
       " '05-16-2021.csv',\n",
       " '05-17-2021.csv',\n",
       " '05-18-2021.csv',\n",
       " '05-19-2021.csv',\n",
       " '05-20-2021.csv',\n",
       " '05-21-2021.csv',\n",
       " '05-22-2021.csv',\n",
       " '05-23-2021.csv',\n",
       " '05-24-2021.csv',\n",
       " '05-25-2021.csv',\n",
       " '05-26-2021.csv',\n",
       " '05-27-2021.csv',\n",
       " '05-28-2021.csv',\n",
       " '05-29-2021.csv',\n",
       " '05-30-2021.csv',\n",
       " '05-31-2021.csv',\n",
       " '06-01-2021.csv',\n",
       " '06-02-2021.csv',\n",
       " '06-03-2021.csv',\n",
       " '06-04-2021.csv',\n",
       " '06-05-2021.csv',\n",
       " '06-06-2021.csv',\n",
       " '06-07-2021.csv',\n",
       " '06-08-2021.csv',\n",
       " '06-09-2021.csv',\n",
       " '06-10-2021.csv',\n",
       " '06-11-2021.csv',\n",
       " '06-12-2021.csv',\n",
       " '06-13-2021.csv',\n",
       " '06-14-2021.csv',\n",
       " '06-15-2021.csv',\n",
       " '06-16-2021.csv',\n",
       " '06-17-2021.csv',\n",
       " '06-18-2021.csv',\n",
       " '06-19-2021.csv',\n",
       " '06-20-2021.csv',\n",
       " '06-21-2021.csv',\n",
       " '06-22-2021.csv',\n",
       " '06-23-2021.csv',\n",
       " '06-24-2021.csv',\n",
       " '06-25-2021.csv',\n",
       " '06-26-2021.csv',\n",
       " '06-27-2021.csv',\n",
       " '06-28-2021.csv',\n",
       " '06-29-2021.csv',\n",
       " '06-30-2021.csv',\n",
       " '07-01-2021.csv',\n",
       " '07-02-2021.csv',\n",
       " '07-03-2021.csv',\n",
       " '07-04-2021.csv',\n",
       " '07-05-2021.csv',\n",
       " '07-06-2021.csv',\n",
       " '07-07-2021.csv',\n",
       " '07-08-2021.csv',\n",
       " '07-09-2021.csv',\n",
       " '07-10-2021.csv',\n",
       " '07-11-2021.csv',\n",
       " '07-12-2021.csv',\n",
       " '07-13-2021.csv',\n",
       " '07-14-2021.csv',\n",
       " '07-15-2021.csv',\n",
       " '07-16-2021.csv',\n",
       " '07-17-2021.csv',\n",
       " '07-18-2021.csv',\n",
       " '07-19-2021.csv',\n",
       " '07-20-2021.csv',\n",
       " '07-21-2021.csv',\n",
       " '07-22-2021.csv',\n",
       " '07-23-2021.csv',\n",
       " '07-24-2021.csv',\n",
       " '07-25-2021.csv',\n",
       " '07-26-2021.csv',\n",
       " '07-27-2021.csv',\n",
       " '07-28-2021.csv',\n",
       " '07-29-2021.csv',\n",
       " '07-30-2021.csv',\n",
       " '07-31-2021.csv',\n",
       " '08-01-2021.csv',\n",
       " '08-02-2021.csv',\n",
       " '08-03-2021.csv',\n",
       " '08-04-2021.csv',\n",
       " '08-05-2021.csv',\n",
       " '08-06-2021.csv',\n",
       " '08-07-2021.csv',\n",
       " '08-08-2021.csv',\n",
       " '08-09-2021.csv',\n",
       " '08-10-2021.csv',\n",
       " '08-11-2021.csv',\n",
       " '08-12-2021.csv',\n",
       " '08-13-2021.csv',\n",
       " '08-14-2021.csv',\n",
       " '08-15-2021.csv',\n",
       " '08-16-2021.csv',\n",
       " '08-17-2021.csv',\n",
       " '08-18-2021.csv',\n",
       " '08-19-2021.csv',\n",
       " '08-20-2021.csv',\n",
       " '08-21-2021.csv',\n",
       " '08-22-2021.csv',\n",
       " '08-23-2021.csv',\n",
       " '08-24-2021.csv',\n",
       " '08-25-2021.csv',\n",
       " '08-26-2021.csv',\n",
       " '08-27-2021.csv',\n",
       " '08-28-2021.csv',\n",
       " '08-29-2021.csv',\n",
       " '08-30-2021.csv',\n",
       " '08-31-2021.csv',\n",
       " '09-01-2021.csv',\n",
       " '09-02-2021.csv',\n",
       " '09-03-2021.csv',\n",
       " '09-04-2021.csv',\n",
       " '09-05-2021.csv',\n",
       " '09-06-2021.csv',\n",
       " '09-07-2021.csv',\n",
       " '09-08-2021.csv',\n",
       " '09-09-2021.csv',\n",
       " '09-10-2021.csv',\n",
       " '09-11-2021.csv',\n",
       " '09-12-2021.csv',\n",
       " '09-13-2021.csv',\n",
       " '09-14-2021.csv',\n",
       " '09-15-2021.csv',\n",
       " '09-16-2021.csv',\n",
       " '09-17-2021.csv',\n",
       " '09-18-2021.csv',\n",
       " '09-19-2021.csv',\n",
       " '09-20-2021.csv',\n",
       " '09-21-2021.csv',\n",
       " '09-22-2021.csv',\n",
       " '09-23-2021.csv',\n",
       " '09-24-2021.csv',\n",
       " '09-25-2021.csv',\n",
       " '09-26-2021.csv',\n",
       " '09-27-2021.csv',\n",
       " '09-28-2021.csv',\n",
       " '09-29-2021.csv',\n",
       " '09-30-2021.csv',\n",
       " '10-01-2021.csv',\n",
       " '10-02-2021.csv',\n",
       " '10-03-2021.csv',\n",
       " '10-04-2021.csv',\n",
       " '10-05-2021.csv',\n",
       " '10-06-2021.csv',\n",
       " '10-07-2021.csv',\n",
       " '10-08-2021.csv',\n",
       " '10-09-2021.csv',\n",
       " '10-10-2021.csv',\n",
       " '10-11-2021.csv',\n",
       " '10-12-2021.csv',\n",
       " '10-13-2021.csv',\n",
       " '10-14-2021.csv',\n",
       " '10-15-2021.csv',\n",
       " '10-16-2021.csv',\n",
       " '10-17-2021.csv',\n",
       " '10-18-2021.csv',\n",
       " '10-19-2021.csv',\n",
       " '10-20-2021.csv',\n",
       " '10-21-2021.csv',\n",
       " '10-22-2021.csv',\n",
       " '10-23-2021.csv',\n",
       " '10-24-2021.csv',\n",
       " '10-25-2021.csv',\n",
       " '10-26-2021.csv',\n",
       " '10-27-2021.csv',\n",
       " '10-28-2021.csv',\n",
       " '10-29-2021.csv',\n",
       " '10-30-2021.csv',\n",
       " '10-31-2021.csv',\n",
       " '11-01-2021.csv',\n",
       " '11-02-2021.csv',\n",
       " '11-03-2021.csv',\n",
       " '11-04-2021.csv',\n",
       " '11-05-2021.csv',\n",
       " '11-06-2021.csv',\n",
       " '11-07-2021.csv',\n",
       " '11-08-2021.csv',\n",
       " '11-09-2021.csv',\n",
       " '11-10-2021.csv',\n",
       " '11-11-2021.csv',\n",
       " '11-12-2021.csv',\n",
       " '11-13-2021.csv',\n",
       " '11-14-2021.csv',\n",
       " '11-15-2021.csv',\n",
       " '11-16-2021.csv',\n",
       " '11-17-2021.csv',\n",
       " '11-18-2021.csv',\n",
       " '11-19-2021.csv',\n",
       " '11-20-2021.csv',\n",
       " '11-21-2021.csv',\n",
       " '11-22-2021.csv',\n",
       " '11-23-2021.csv',\n",
       " '11-24-2021.csv',\n",
       " '11-25-2021.csv',\n",
       " '11-26-2021.csv',\n",
       " '11-27-2021.csv',\n",
       " '11-28-2021.csv',\n",
       " '11-29-2021.csv',\n",
       " '11-30-2021.csv',\n",
       " '12-01-2021.csv',\n",
       " '12-02-2021.csv',\n",
       " '12-03-2021.csv',\n",
       " '12-04-2021.csv',\n",
       " '12-05-2021.csv',\n",
       " '12-06-2021.csv',\n",
       " '12-07-2021.csv',\n",
       " '12-08-2021.csv',\n",
       " '12-09-2021.csv',\n",
       " '12-10-2021.csv',\n",
       " '12-11-2021.csv',\n",
       " '12-12-2021.csv',\n",
       " '12-13-2021.csv',\n",
       " '12-14-2021.csv',\n",
       " '12-15-2021.csv',\n",
       " '12-16-2021.csv',\n",
       " '12-17-2021.csv',\n",
       " '12-18-2021.csv',\n",
       " '12-19-2021.csv',\n",
       " '12-20-2021.csv',\n",
       " '12-21-2021.csv',\n",
       " '12-22-2021.csv',\n",
       " '12-23-2021.csv',\n",
       " '12-24-2021.csv',\n",
       " '12-25-2021.csv',\n",
       " '12-26-2021.csv',\n",
       " '12-27-2021.csv',\n",
       " '12-28-2021.csv',\n",
       " '12-29-2021.csv',\n",
       " '12-30-2021.csv',\n",
       " '12-31-2021.csv',\n",
       " '01-01-2022.csv',\n",
       " '01-02-2022.csv',\n",
       " '01-03-2022.csv',\n",
       " '01-04-2022.csv',\n",
       " '01-05-2022.csv',\n",
       " '01-06-2022.csv',\n",
       " '01-07-2022.csv',\n",
       " '01-08-2022.csv',\n",
       " '01-09-2022.csv',\n",
       " '01-10-2022.csv',\n",
       " '01-11-2022.csv',\n",
       " '01-12-2022.csv',\n",
       " '01-13-2022.csv',\n",
       " '01-14-2022.csv',\n",
       " '01-15-2022.csv',\n",
       " '01-16-2022.csv',\n",
       " '01-17-2022.csv',\n",
       " '01-18-2022.csv',\n",
       " '01-19-2022.csv',\n",
       " '01-20-2022.csv',\n",
       " '01-21-2022.csv',\n",
       " '01-22-2022.csv',\n",
       " '01-23-2022.csv',\n",
       " '01-24-2022.csv',\n",
       " '01-25-2022.csv',\n",
       " '01-26-2022.csv',\n",
       " '01-27-2022.csv',\n",
       " '01-28-2022.csv',\n",
       " '01-29-2022.csv',\n",
       " '01-30-2022.csv',\n",
       " '01-31-2022.csv',\n",
       " '02-01-2022.csv',\n",
       " '02-02-2022.csv',\n",
       " '02-03-2022.csv',\n",
       " '02-04-2022.csv',\n",
       " '02-05-2022.csv',\n",
       " '02-06-2022.csv',\n",
       " '02-07-2022.csv',\n",
       " '02-08-2022.csv',\n",
       " '02-09-2022.csv',\n",
       " '02-10-2022.csv',\n",
       " '02-11-2022.csv',\n",
       " '02-12-2022.csv',\n",
       " '02-13-2022.csv',\n",
       " '02-14-2022.csv',\n",
       " '02-15-2022.csv',\n",
       " '02-16-2022.csv',\n",
       " '02-17-2022.csv',\n",
       " '02-18-2022.csv',\n",
       " '02-19-2022.csv',\n",
       " '02-20-2022.csv',\n",
       " '02-21-2022.csv',\n",
       " '02-22-2022.csv',\n",
       " '02-23-2022.csv',\n",
       " '02-24-2022.csv',\n",
       " '02-25-2022.csv',\n",
       " '02-26-2022.csv',\n",
       " '02-27-2022.csv',\n",
       " '02-28-2022.csv',\n",
       " '03-01-2022.csv',\n",
       " '03-02-2022.csv',\n",
       " '03-03-2022.csv',\n",
       " '03-04-2022.csv',\n",
       " '03-05-2022.csv',\n",
       " '03-06-2022.csv',\n",
       " '03-07-2022.csv',\n",
       " '03-08-2022.csv',\n",
       " '03-09-2022.csv',\n",
       " '03-10-2022.csv',\n",
       " '03-11-2022.csv',\n",
       " '03-12-2022.csv',\n",
       " '03-13-2022.csv',\n",
       " '03-14-2022.csv',\n",
       " '03-15-2022.csv',\n",
       " '03-16-2022.csv',\n",
       " '03-17-2022.csv',\n",
       " '03-18-2022.csv',\n",
       " '03-19-2022.csv',\n",
       " '03-20-2022.csv',\n",
       " '03-21-2022.csv',\n",
       " '03-22-2022.csv',\n",
       " '03-23-2022.csv',\n",
       " '03-24-2022.csv',\n",
       " '03-25-2022.csv',\n",
       " '03-26-2022.csv',\n",
       " '03-27-2022.csv',\n",
       " '03-28-2022.csv',\n",
       " '03-29-2022.csv',\n",
       " '03-30-2022.csv',\n",
       " '03-31-2022.csv',\n",
       " '04-01-2022.csv',\n",
       " '04-02-2022.csv',\n",
       " '04-03-2022.csv',\n",
       " '04-04-2022.csv',\n",
       " '04-05-2022.csv',\n",
       " '04-06-2022.csv',\n",
       " '04-07-2022.csv',\n",
       " '04-08-2022.csv',\n",
       " '04-09-2022.csv',\n",
       " '04-10-2022.csv',\n",
       " '04-11-2022.csv',\n",
       " '04-12-2022.csv',\n",
       " '04-13-2022.csv',\n",
       " '04-14-2022.csv',\n",
       " '04-15-2022.csv',\n",
       " '04-16-2022.csv',\n",
       " '04-17-2022.csv',\n",
       " '04-18-2022.csv',\n",
       " '04-19-2022.csv',\n",
       " '04-20-2022.csv',\n",
       " '04-21-2022.csv',\n",
       " '04-22-2022.csv',\n",
       " '04-23-2022.csv',\n",
       " '04-24-2022.csv',\n",
       " '04-25-2022.csv',\n",
       " '04-26-2022.csv',\n",
       " '04-27-2022.csv',\n",
       " '04-28-2022.csv',\n",
       " '04-29-2022.csv',\n",
       " '04-30-2022.csv',\n",
       " '05-01-2022.csv',\n",
       " '05-02-2022.csv',\n",
       " '05-03-2022.csv',\n",
       " '05-04-2022.csv',\n",
       " '05-05-2022.csv',\n",
       " '05-06-2022.csv',\n",
       " '05-07-2022.csv',\n",
       " '05-08-2022.csv',\n",
       " '05-09-2022.csv',\n",
       " '05-10-2022.csv',\n",
       " '05-11-2022.csv',\n",
       " '05-12-2022.csv',\n",
       " '05-13-2022.csv',\n",
       " '05-14-2022.csv',\n",
       " '05-15-2022.csv',\n",
       " '05-16-2022.csv',\n",
       " '05-17-2022.csv',\n",
       " '05-18-2022.csv',\n",
       " '05-19-2022.csv',\n",
       " '05-20-2022.csv',\n",
       " '05-21-2022.csv',\n",
       " '05-22-2022.csv',\n",
       " '05-23-2022.csv',\n",
       " '05-24-2022.csv',\n",
       " '05-25-2022.csv',\n",
       " '05-26-2022.csv',\n",
       " '05-27-2022.csv',\n",
       " '05-28-2022.csv',\n",
       " '05-29-2022.csv',\n",
       " '05-30-2022.csv',\n",
       " '05-31-2022.csv',\n",
       " '06-01-2022.csv',\n",
       " '06-02-2022.csv',\n",
       " '06-03-2022.csv',\n",
       " '06-04-2022.csv',\n",
       " '06-05-2022.csv',\n",
       " '06-06-2022.csv',\n",
       " '06-07-2022.csv',\n",
       " '06-08-2022.csv',\n",
       " '06-09-2022.csv',\n",
       " '06-10-2022.csv',\n",
       " '06-11-2022.csv',\n",
       " '06-12-2022.csv',\n",
       " '06-13-2022.csv',\n",
       " '06-14-2022.csv',\n",
       " '06-15-2022.csv',\n",
       " '06-16-2022.csv',\n",
       " '06-17-2022.csv',\n",
       " '06-18-2022.csv',\n",
       " '06-19-2022.csv',\n",
       " '06-20-2022.csv',\n",
       " '06-21-2022.csv',\n",
       " '06-22-2022.csv',\n",
       " '06-23-2022.csv',\n",
       " '06-24-2022.csv',\n",
       " '06-25-2022.csv',\n",
       " '06-26-2022.csv',\n",
       " '06-27-2022.csv',\n",
       " '06-28-2022.csv',\n",
       " '06-29-2022.csv',\n",
       " '06-30-2022.csv',\n",
       " '07-01-2022.csv',\n",
       " '07-02-2022.csv',\n",
       " '07-03-2022.csv',\n",
       " '07-04-2022.csv',\n",
       " '07-05-2022.csv',\n",
       " '07-06-2022.csv',\n",
       " '07-07-2022.csv',\n",
       " '07-08-2022.csv',\n",
       " '07-09-2022.csv',\n",
       " '07-10-2022.csv',\n",
       " '07-11-2022.csv',\n",
       " '07-12-2022.csv',\n",
       " '07-13-2022.csv',\n",
       " '07-14-2022.csv',\n",
       " '07-15-2022.csv',\n",
       " '07-16-2022.csv',\n",
       " '07-17-2022.csv',\n",
       " '07-18-2022.csv',\n",
       " '07-19-2022.csv',\n",
       " '07-20-2022.csv',\n",
       " '07-21-2022.csv',\n",
       " '07-22-2022.csv',\n",
       " '07-23-2022.csv',\n",
       " '07-24-2022.csv',\n",
       " '07-25-2022.csv',\n",
       " '07-26-2022.csv',\n",
       " '07-27-2022.csv',\n",
       " '07-28-2022.csv',\n",
       " '07-29-2022.csv',\n",
       " '07-30-2022.csv',\n",
       " '07-31-2022.csv',\n",
       " '08-01-2022.csv',\n",
       " '08-02-2022.csv',\n",
       " '08-03-2022.csv',\n",
       " '08-04-2022.csv',\n",
       " '08-05-2022.csv',\n",
       " '08-06-2022.csv',\n",
       " '08-07-2022.csv',\n",
       " '08-08-2022.csv',\n",
       " '08-09-2022.csv',\n",
       " '08-10-2022.csv',\n",
       " '08-11-2022.csv',\n",
       " '08-12-2022.csv',\n",
       " '08-13-2022.csv',\n",
       " '08-14-2022.csv',\n",
       " '08-15-2022.csv',\n",
       " '08-16-2022.csv',\n",
       " '08-17-2022.csv',\n",
       " '08-18-2022.csv',\n",
       " '08-19-2022.csv',\n",
       " '08-20-2022.csv',\n",
       " '08-21-2022.csv',\n",
       " '08-22-2022.csv',\n",
       " '08-23-2022.csv',\n",
       " '08-24-2022.csv',\n",
       " '08-25-2022.csv',\n",
       " '08-26-2022.csv',\n",
       " '08-27-2022.csv',\n",
       " '08-28-2022.csv',\n",
       " '08-29-2022.csv',\n",
       " '08-30-2022.csv',\n",
       " '08-31-2022.csv',\n",
       " '09-01-2022.csv',\n",
       " '09-02-2022.csv',\n",
       " '09-03-2022.csv',\n",
       " '09-04-2022.csv',\n",
       " '09-05-2022.csv',\n",
       " '09-06-2022.csv',\n",
       " '09-07-2022.csv',\n",
       " '09-08-2022.csv',\n",
       " '09-09-2022.csv',\n",
       " '09-10-2022.csv',\n",
       " '09-11-2022.csv',\n",
       " '09-12-2022.csv',\n",
       " '09-13-2022.csv',\n",
       " '09-14-2022.csv',\n",
       " '09-15-2022.csv',\n",
       " '09-16-2022.csv',\n",
       " '09-17-2022.csv',\n",
       " '09-18-2022.csv',\n",
       " '09-19-2022.csv',\n",
       " '09-20-2022.csv',\n",
       " '09-21-2022.csv',\n",
       " '09-22-2022.csv',\n",
       " '09-23-2022.csv',\n",
       " '09-24-2022.csv',\n",
       " '09-25-2022.csv',\n",
       " '09-26-2022.csv',\n",
       " '09-27-2022.csv',\n",
       " '09-28-2022.csv',\n",
       " '09-29-2022.csv',\n",
       " '09-30-2022.csv',\n",
       " '10-01-2022.csv',\n",
       " '10-02-2022.csv',\n",
       " '10-03-2022.csv',\n",
       " '10-04-2022.csv',\n",
       " '10-05-2022.csv',\n",
       " '10-06-2022.csv',\n",
       " '10-07-2022.csv',\n",
       " '10-08-2022.csv',\n",
       " '10-09-2022.csv',\n",
       " '10-10-2022.csv',\n",
       " '10-11-2022.csv',\n",
       " '10-12-2022.csv',\n",
       " '10-13-2022.csv',\n",
       " '10-14-2022.csv',\n",
       " '10-15-2022.csv',\n",
       " '10-16-2022.csv',\n",
       " '10-17-2022.csv',\n",
       " ...]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2024.05 업데이트\n",
    "# 파일명이 06-15-2020.csv 으로 날짜로 되어 있으며, 이를 단순히 sort() 로 정렬할 경우, 날짜가 06-15-2021.csv 와 같이 연도를 넘어갈 경우 \n",
    "# 날짜 순서대로 정렬이 안될 수 있음\n",
    "# 따라서, 날짜 순으로 정렬이 정확히 될 수 있도록 문법을 개선함 (단, 관련 문법이 복잡하기 때문에 바로 다음 참고를 통해 참고 설명을 추가함)\n",
    "# csv_list.sort()\n",
    "from datetime import datetime\n",
    "csv_list.sort(key=lambda x: datetime.strptime(x, '%m-%d-%Y.csv'))\n",
    "csv_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 참고: 날짜 형식에 따라 파일 이름 정렬하기\n",
    "\n",
    "목표: `csv_list`에 포함된 파일 이름을 날짜 순서대로 정렬합니다. 파일 이름 형식은 `MM-DD-YYYY.csv`입니다.\n",
    "\n",
    "#### 1. datetime 모듈의 사용\n",
    "\n",
    "Python의 `datetime` 모듈을 사용하여 문자열을 `datetime` 객체로 변환합니다.\n",
    "\n",
    "```python\n",
    "from datetime import datetime\n",
    "```\n",
    "\n",
    "#### 2. lambda 함수\n",
    "\n",
    "`lambda`는 익명 함수(이름이 없는 함수)를 생성하는 Python의 기능입니다. 여기서는 `lambda`를 사용하여 파일 이름을 `datetime` 객체로 변환합니다.\n",
    "\n",
    "```python\n",
    "lambda x: datetime.strptime(x, '%m-%d-%Y.csv')\n",
    "```\n",
    "\n",
    "이 부분을 이해하기 위해, `lambda`와 `datetime.strptime`에 대해 자세히 설명하겠습니다.\n",
    "\n",
    "##### lambda 함수\n",
    "\n",
    "- `lambda` 함수는 짧은 함수 정의를 할 때 사용됩니다.\n",
    "- 일반 함수 정의와 달리, `lambda` 함수는 `lambda` 키워드를 사용하여 한 줄로 작성됩니다.\n",
    "- 예시:\n",
    "  ```python\n",
    "  def add(a, b):\n",
    "      return a + b\n",
    "\n",
    "  # 위 함수는 아래와 같이 lambda 함수로 표현할 수 있습니다.\n",
    "  add = lambda a, b: a + b\n",
    "  ```\n",
    "- 여기서는 `x`를 입력으로 받아 `datetime.strptime(x, '%m-%d-%Y.csv')`를 반환하는 함수입니다.\n",
    "\n",
    "##### datetime.strptime 함수\n",
    "\n",
    "- `datetime.strptime` 함수는 문자열을 `datetime` 객체로 변환합니다.\n",
    "- 첫 번째 인자는 변환할 문자열이고, 두 번째 인자는 문자열의 형식을 지정하는 형식 문자열입니다.\n",
    "- 형식 문자열의 주요 옵션:\n",
    "  - `%m`: 월 (01에서 12)\n",
    "  - `%d`: 일 (01에서 31)\n",
    "  - `%Y`: 연도 (예: 2021)\n",
    "- 예시:\n",
    "  ```python\n",
    "  date_str = '01-01-2021.csv'\n",
    "  date_obj = datetime.strptime(date_str, '%m-%d-%Y.csv')\n",
    "  ```\n",
    "\n",
    "#### 3. sort 함수의 key 매개변수\n",
    "\n",
    "- `sort` 함수는 리스트를 정렬하는 메서드입니다.\n",
    "- `key` 매개변수를 사용하여 정렬 기준을 지정할 수 있습니다.\n",
    "- `key`에 함수를 지정하면, 리스트의 각 요소에 대해 해당 함수가 호출되어 반환된 값을 기준으로 정렬합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['01-01-2021.csv', '01-01-2022.csv', '01-01-2023.csv', '01-02-2021.csv', '01-02-2022.csv', '01-02-2023.csv', '01-03-2021.csv', '01-03-2022.csv', '01-03-2023.csv', '01-04-2021.csv', '01-04-2022.csv', '01-04-2023.csv', '01-05-2021.csv', '01-05-2022.csv', '01-05-2023.csv', '01-06-2021.csv', '01-06-2022.csv', '01-06-2023.csv']\n",
      "['01-01-2021.csv', '01-02-2021.csv', '01-03-2021.csv', '01-04-2021.csv', '01-05-2021.csv', '01-06-2021.csv', '01-01-2022.csv', '01-02-2022.csv', '01-03-2022.csv', '01-04-2022.csv', '01-05-2022.csv', '01-06-2022.csv', '01-01-2023.csv', '01-02-2023.csv', '01-03-2023.csv', '01-04-2023.csv', '01-05-2023.csv', '01-06-2023.csv']\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# 예시 csv_list_test\n",
    "csv_list_test = [\n",
    "    '01-01-2021.csv', '01-01-2022.csv', '01-01-2023.csv', \n",
    "    '01-02-2021.csv', '01-02-2022.csv', '01-02-2023.csv', \n",
    "    '01-03-2021.csv', '01-03-2022.csv', '01-03-2023.csv', \n",
    "    '01-04-2021.csv', '01-04-2022.csv', '01-04-2023.csv', \n",
    "    '01-05-2021.csv', '01-05-2022.csv', '01-05-2023.csv', \n",
    "    '01-06-2021.csv', '01-06-2022.csv', '01-06-2023.csv'\n",
    "]\n",
    "\n",
    "# csv_list의 내용을 날짜 형식으로 정렬하지 않았을 경우\n",
    "csv_list_test.sort()\n",
    "print(csv_list_test)\n",
    "\n",
    "# csv_list의 내용을 날짜 형식으로 정렬하기\n",
    "csv_list_test.sort(key=lambda x: datetime.strptime(x, '%m-%d-%Y.csv'))\n",
    "print(csv_list_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 여러 데이터 수집, 전처리해서, 하나의 데이터프레임 만들기\n",
    "- 지금까지의 과정을 모두 한데 모아서, 함수로 만들기\n",
    "  1. 필요한 파일 리스트만 추출하기\n",
    "  2. 파일 리스트 정렬하기\n",
    "  3. 데이터프레임 전처리하기 (별도 create_dateframe() 함수)\n",
    "  4. 데이터프레임 합치기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 최종 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "with open('COVID-19-master/csse_covid_19_data/country_convert.json', 'r', encoding='utf-8-sig') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "\n",
    "def country_name_convert(row):\n",
    "    if row['Country_Region'] in json_data:\n",
    "        return json_data[row['Country_Region']]\n",
    "    return row['Country_Region']\n",
    "\n",
    "def create_dateframe(filename):\n",
    "\n",
    "    doc = pd.read_csv(PATH + filename, encoding='utf-8-sig')  # 1. csv 파일 읽기\n",
    "    try:\n",
    "        doc = doc[['Country_Region', 'Confirmed']]  # 2. 특정 컬럼만 선택해서 데이터프레임 만들기\n",
    "    except:\n",
    "        doc = doc[['Country/Region', 'Confirmed']]  # 2. 특정 컬럼만 선택해서 데이터프레임 만들기\n",
    "        doc.columns = ['Country_Region', 'Confirmed']\n",
    "    doc = doc.dropna(subset=['Confirmed'])     # 3. 특정 컬럼에 없는 데이터 삭제하기\n",
    "    doc['Country_Region'] = doc.apply(country_name_convert, axis=1)   # 4. 'Country_Region'의 국가명을 여러 파일에 일관되게 변경하기\n",
    "    doc = doc.astype({'Confirmed': 'int64'})   # 5. 특정 컬럼의 데이터 타입 변경하기\n",
    "    doc = doc.groupby('Country_Region').sum()  # 6. 특정 컬럼으로 중복된 데이터를 합치기\n",
    "\n",
    "    # 7. 파일명을 기반으로 날짜 문자열 변환하고, 'Confirmed' 컬럼명 변경하기\n",
    "    date_column = filename.split(\".\")[0].lstrip('0').replace('-', '/') \n",
    "    doc.columns = [date_column]\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def generate_dateframe_by_path(PATH):\n",
    "\n",
    "    file_list, csv_list = os.listdir(PATH), list()\n",
    "    first_doc = True\n",
    "    for file in file_list:\n",
    "        if file.split(\".\")[-1] == 'csv':\n",
    "            csv_list.append(file)\n",
    "    # 2024.05 업데이트\n",
    "    # 단순 정렬이 아닌, 날짜 형식에 따라 정확히 정렬하도록 정렬 코드 개선\n",
    "    # csv_list.sort()\n",
    "    csv_list.sort(key=lambda x: datetime.strptime(x, '%m-%d-%Y.csv'))\n",
    "    \n",
    "    \n",
    "    for file in csv_list:\n",
    "        doc = create_dateframe(file)\n",
    "        if first_doc:\n",
    "            final_doc, first_doc = doc, False\n",
    "        else:\n",
    "            final_doc = pd.merge(final_doc, doc, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "    final_doc = final_doc.fillna(0)\n",
    "    return final_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1/22/2020</th>\n",
       "      <th>1/23/2020</th>\n",
       "      <th>1/24/2020</th>\n",
       "      <th>1/25/2020</th>\n",
       "      <th>1/26/2020</th>\n",
       "      <th>1/27/2020</th>\n",
       "      <th>1/28/2020</th>\n",
       "      <th>1/29/2020</th>\n",
       "      <th>1/30/2020</th>\n",
       "      <th>1/31/2020</th>\n",
       "      <th>...</th>\n",
       "      <th>2/28/2023</th>\n",
       "      <th>3/01/2023</th>\n",
       "      <th>3/02/2023</th>\n",
       "      <th>3/03/2023</th>\n",
       "      <th>3/04/2023</th>\n",
       "      <th>3/05/2023</th>\n",
       "      <th>3/06/2023</th>\n",
       "      <th>3/07/2023</th>\n",
       "      <th>3/08/2023</th>\n",
       "      <th>3/09/2023</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country_Region</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Afghanistan</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>209322.0</td>\n",
       "      <td>209340.0</td>\n",
       "      <td>209358.0</td>\n",
       "      <td>209362.0</td>\n",
       "      <td>209369.0</td>\n",
       "      <td>209390.0</td>\n",
       "      <td>209406.0</td>\n",
       "      <td>209436.0</td>\n",
       "      <td>209451.0</td>\n",
       "      <td>209451.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albania</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>334391.0</td>\n",
       "      <td>334408.0</td>\n",
       "      <td>334408.0</td>\n",
       "      <td>334427.0</td>\n",
       "      <td>334427.0</td>\n",
       "      <td>334427.0</td>\n",
       "      <td>334427.0</td>\n",
       "      <td>334427.0</td>\n",
       "      <td>334443.0</td>\n",
       "      <td>334457.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algeria</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>271441.0</td>\n",
       "      <td>271448.0</td>\n",
       "      <td>271463.0</td>\n",
       "      <td>271469.0</td>\n",
       "      <td>271469.0</td>\n",
       "      <td>271477.0</td>\n",
       "      <td>271477.0</td>\n",
       "      <td>271490.0</td>\n",
       "      <td>271494.0</td>\n",
       "      <td>271496.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Andorra</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>47866.0</td>\n",
       "      <td>47875.0</td>\n",
       "      <td>47875.0</td>\n",
       "      <td>47875.0</td>\n",
       "      <td>47875.0</td>\n",
       "      <td>47875.0</td>\n",
       "      <td>47875.0</td>\n",
       "      <td>47875.0</td>\n",
       "      <td>47890.0</td>\n",
       "      <td>47890.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Angola</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>105255.0</td>\n",
       "      <td>105277.0</td>\n",
       "      <td>105277.0</td>\n",
       "      <td>105277.0</td>\n",
       "      <td>105277.0</td>\n",
       "      <td>105277.0</td>\n",
       "      <td>105277.0</td>\n",
       "      <td>105277.0</td>\n",
       "      <td>105288.0</td>\n",
       "      <td>105288.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West Bank and Gaza</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>703228.0</td>\n",
       "      <td>703228.0</td>\n",
       "      <td>703228.0</td>\n",
       "      <td>703228.0</td>\n",
       "      <td>703228.0</td>\n",
       "      <td>703228.0</td>\n",
       "      <td>703228.0</td>\n",
       "      <td>703228.0</td>\n",
       "      <td>703228.0</td>\n",
       "      <td>703228.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Winter Olympics 2022</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>535.0</td>\n",
       "      <td>535.0</td>\n",
       "      <td>535.0</td>\n",
       "      <td>535.0</td>\n",
       "      <td>535.0</td>\n",
       "      <td>535.0</td>\n",
       "      <td>535.0</td>\n",
       "      <td>535.0</td>\n",
       "      <td>535.0</td>\n",
       "      <td>535.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yemen</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11945.0</td>\n",
       "      <td>11945.0</td>\n",
       "      <td>11945.0</td>\n",
       "      <td>11945.0</td>\n",
       "      <td>11945.0</td>\n",
       "      <td>11945.0</td>\n",
       "      <td>11945.0</td>\n",
       "      <td>11945.0</td>\n",
       "      <td>11945.0</td>\n",
       "      <td>11945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zambia</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>343012.0</td>\n",
       "      <td>343012.0</td>\n",
       "      <td>343079.0</td>\n",
       "      <td>343079.0</td>\n",
       "      <td>343079.0</td>\n",
       "      <td>343135.0</td>\n",
       "      <td>343135.0</td>\n",
       "      <td>343135.0</td>\n",
       "      <td>343135.0</td>\n",
       "      <td>343135.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zimbabwe</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>263921.0</td>\n",
       "      <td>264127.0</td>\n",
       "      <td>264127.0</td>\n",
       "      <td>264127.0</td>\n",
       "      <td>264127.0</td>\n",
       "      <td>264127.0</td>\n",
       "      <td>264127.0</td>\n",
       "      <td>264127.0</td>\n",
       "      <td>264276.0</td>\n",
       "      <td>264276.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201 rows × 1143 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      1/22/2020  1/23/2020  1/24/2020  1/25/2020  1/26/2020  \\\n",
       "Country_Region                                                                \n",
       "Afghanistan                 0.0        0.0        0.0        0.0        0.0   \n",
       "Albania                     0.0        0.0        0.0        0.0        0.0   \n",
       "Algeria                     0.0        0.0        0.0        0.0        0.0   \n",
       "Andorra                     0.0        0.0        0.0        0.0        0.0   \n",
       "Angola                      0.0        0.0        0.0        0.0        0.0   \n",
       "...                         ...        ...        ...        ...        ...   \n",
       "West Bank and Gaza          0.0        0.0        0.0        0.0        0.0   \n",
       "Winter Olympics 2022        0.0        0.0        0.0        0.0        0.0   \n",
       "Yemen                       0.0        0.0        0.0        0.0        0.0   \n",
       "Zambia                      0.0        0.0        0.0        0.0        0.0   \n",
       "Zimbabwe                    0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "                      1/27/2020  1/28/2020  1/29/2020  1/30/2020  1/31/2020  \\\n",
       "Country_Region                                                                \n",
       "Afghanistan                 0.0        0.0        0.0        0.0        0.0   \n",
       "Albania                     0.0        0.0        0.0        0.0        0.0   \n",
       "Algeria                     0.0        0.0        0.0        0.0        0.0   \n",
       "Andorra                     0.0        0.0        0.0        0.0        0.0   \n",
       "Angola                      0.0        0.0        0.0        0.0        0.0   \n",
       "...                         ...        ...        ...        ...        ...   \n",
       "West Bank and Gaza          0.0        0.0        0.0        0.0        0.0   \n",
       "Winter Olympics 2022        0.0        0.0        0.0        0.0        0.0   \n",
       "Yemen                       0.0        0.0        0.0        0.0        0.0   \n",
       "Zambia                      0.0        0.0        0.0        0.0        0.0   \n",
       "Zimbabwe                    0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "                      ...  2/28/2023  3/01/2023  3/02/2023  3/03/2023  \\\n",
       "Country_Region        ...                                               \n",
       "Afghanistan           ...   209322.0   209340.0   209358.0   209362.0   \n",
       "Albania               ...   334391.0   334408.0   334408.0   334427.0   \n",
       "Algeria               ...   271441.0   271448.0   271463.0   271469.0   \n",
       "Andorra               ...    47866.0    47875.0    47875.0    47875.0   \n",
       "Angola                ...   105255.0   105277.0   105277.0   105277.0   \n",
       "...                   ...        ...        ...        ...        ...   \n",
       "West Bank and Gaza    ...   703228.0   703228.0   703228.0   703228.0   \n",
       "Winter Olympics 2022  ...      535.0      535.0      535.0      535.0   \n",
       "Yemen                 ...    11945.0    11945.0    11945.0    11945.0   \n",
       "Zambia                ...   343012.0   343012.0   343079.0   343079.0   \n",
       "Zimbabwe              ...   263921.0   264127.0   264127.0   264127.0   \n",
       "\n",
       "                      3/04/2023  3/05/2023  3/06/2023  3/07/2023  3/08/2023  \\\n",
       "Country_Region                                                                \n",
       "Afghanistan            209369.0   209390.0   209406.0   209436.0   209451.0   \n",
       "Albania                334427.0   334427.0   334427.0   334427.0   334443.0   \n",
       "Algeria                271469.0   271477.0   271477.0   271490.0   271494.0   \n",
       "Andorra                 47875.0    47875.0    47875.0    47875.0    47890.0   \n",
       "Angola                 105277.0   105277.0   105277.0   105277.0   105288.0   \n",
       "...                         ...        ...        ...        ...        ...   \n",
       "West Bank and Gaza     703228.0   703228.0   703228.0   703228.0   703228.0   \n",
       "Winter Olympics 2022      535.0      535.0      535.0      535.0      535.0   \n",
       "Yemen                   11945.0    11945.0    11945.0    11945.0    11945.0   \n",
       "Zambia                 343079.0   343135.0   343135.0   343135.0   343135.0   \n",
       "Zimbabwe               264127.0   264127.0   264127.0   264127.0   264276.0   \n",
       "\n",
       "                      3/09/2023  \n",
       "Country_Region                   \n",
       "Afghanistan            209451.0  \n",
       "Albania                334457.0  \n",
       "Algeria                271496.0  \n",
       "Andorra                 47890.0  \n",
       "Angola                 105288.0  \n",
       "...                         ...  \n",
       "West Bank and Gaza     703228.0  \n",
       "Winter Olympics 2022      535.0  \n",
       "Yemen                   11945.0  \n",
       "Zambia                 343135.0  \n",
       "Zimbabwe               264276.0  \n",
       "\n",
       "[201 rows x 1143 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = 'COVID-19-master/csse_covid_19_data/csse_covid_19_daily_reports/'\n",
    "doc = generate_dateframe_by_path(PATH)\n",
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고: 데이터 타입 변환이 가능한 모든 열의 데이터 타입 변경\n",
    "- pd.astype(데이터타입)\n",
    "  - object 는 파이썬의 str 또는 혼용 데이터 타입 (문자열)\n",
    "  - int64 는 파이썬의 int (정수)\n",
    "  - float64 는 파이썬의 float (부동소숫점)\n",
    "  - bool 는 파이썬의 bool (True 또는 False 값을 가지는 boolean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1/22/2020</th>\n",
       "      <th>1/23/2020</th>\n",
       "      <th>1/24/2020</th>\n",
       "      <th>1/25/2020</th>\n",
       "      <th>1/26/2020</th>\n",
       "      <th>1/27/2020</th>\n",
       "      <th>1/28/2020</th>\n",
       "      <th>1/29/2020</th>\n",
       "      <th>1/30/2020</th>\n",
       "      <th>1/31/2020</th>\n",
       "      <th>...</th>\n",
       "      <th>2/28/2023</th>\n",
       "      <th>3/01/2023</th>\n",
       "      <th>3/02/2023</th>\n",
       "      <th>3/03/2023</th>\n",
       "      <th>3/04/2023</th>\n",
       "      <th>3/05/2023</th>\n",
       "      <th>3/06/2023</th>\n",
       "      <th>3/07/2023</th>\n",
       "      <th>3/08/2023</th>\n",
       "      <th>3/09/2023</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country_Region</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Afghanistan</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>209322</td>\n",
       "      <td>209340</td>\n",
       "      <td>209358</td>\n",
       "      <td>209362</td>\n",
       "      <td>209369</td>\n",
       "      <td>209390</td>\n",
       "      <td>209406</td>\n",
       "      <td>209436</td>\n",
       "      <td>209451</td>\n",
       "      <td>209451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albania</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>334391</td>\n",
       "      <td>334408</td>\n",
       "      <td>334408</td>\n",
       "      <td>334427</td>\n",
       "      <td>334427</td>\n",
       "      <td>334427</td>\n",
       "      <td>334427</td>\n",
       "      <td>334427</td>\n",
       "      <td>334443</td>\n",
       "      <td>334457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algeria</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>271441</td>\n",
       "      <td>271448</td>\n",
       "      <td>271463</td>\n",
       "      <td>271469</td>\n",
       "      <td>271469</td>\n",
       "      <td>271477</td>\n",
       "      <td>271477</td>\n",
       "      <td>271490</td>\n",
       "      <td>271494</td>\n",
       "      <td>271496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Andorra</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>47866</td>\n",
       "      <td>47875</td>\n",
       "      <td>47875</td>\n",
       "      <td>47875</td>\n",
       "      <td>47875</td>\n",
       "      <td>47875</td>\n",
       "      <td>47875</td>\n",
       "      <td>47875</td>\n",
       "      <td>47890</td>\n",
       "      <td>47890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Angola</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>105255</td>\n",
       "      <td>105277</td>\n",
       "      <td>105277</td>\n",
       "      <td>105277</td>\n",
       "      <td>105277</td>\n",
       "      <td>105277</td>\n",
       "      <td>105277</td>\n",
       "      <td>105277</td>\n",
       "      <td>105288</td>\n",
       "      <td>105288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West Bank and Gaza</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>703228</td>\n",
       "      <td>703228</td>\n",
       "      <td>703228</td>\n",
       "      <td>703228</td>\n",
       "      <td>703228</td>\n",
       "      <td>703228</td>\n",
       "      <td>703228</td>\n",
       "      <td>703228</td>\n",
       "      <td>703228</td>\n",
       "      <td>703228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Winter Olympics 2022</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>535</td>\n",
       "      <td>535</td>\n",
       "      <td>535</td>\n",
       "      <td>535</td>\n",
       "      <td>535</td>\n",
       "      <td>535</td>\n",
       "      <td>535</td>\n",
       "      <td>535</td>\n",
       "      <td>535</td>\n",
       "      <td>535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yemen</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>11945</td>\n",
       "      <td>11945</td>\n",
       "      <td>11945</td>\n",
       "      <td>11945</td>\n",
       "      <td>11945</td>\n",
       "      <td>11945</td>\n",
       "      <td>11945</td>\n",
       "      <td>11945</td>\n",
       "      <td>11945</td>\n",
       "      <td>11945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zambia</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>343012</td>\n",
       "      <td>343012</td>\n",
       "      <td>343079</td>\n",
       "      <td>343079</td>\n",
       "      <td>343079</td>\n",
       "      <td>343135</td>\n",
       "      <td>343135</td>\n",
       "      <td>343135</td>\n",
       "      <td>343135</td>\n",
       "      <td>343135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zimbabwe</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>263921</td>\n",
       "      <td>264127</td>\n",
       "      <td>264127</td>\n",
       "      <td>264127</td>\n",
       "      <td>264127</td>\n",
       "      <td>264127</td>\n",
       "      <td>264127</td>\n",
       "      <td>264127</td>\n",
       "      <td>264276</td>\n",
       "      <td>264276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201 rows × 1143 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      1/22/2020  1/23/2020  1/24/2020  1/25/2020  1/26/2020  \\\n",
       "Country_Region                                                                \n",
       "Afghanistan                   0          0          0          0          0   \n",
       "Albania                       0          0          0          0          0   \n",
       "Algeria                       0          0          0          0          0   \n",
       "Andorra                       0          0          0          0          0   \n",
       "Angola                        0          0          0          0          0   \n",
       "...                         ...        ...        ...        ...        ...   \n",
       "West Bank and Gaza            0          0          0          0          0   \n",
       "Winter Olympics 2022          0          0          0          0          0   \n",
       "Yemen                         0          0          0          0          0   \n",
       "Zambia                        0          0          0          0          0   \n",
       "Zimbabwe                      0          0          0          0          0   \n",
       "\n",
       "                      1/27/2020  1/28/2020  1/29/2020  1/30/2020  1/31/2020  \\\n",
       "Country_Region                                                                \n",
       "Afghanistan                   0          0          0          0          0   \n",
       "Albania                       0          0          0          0          0   \n",
       "Algeria                       0          0          0          0          0   \n",
       "Andorra                       0          0          0          0          0   \n",
       "Angola                        0          0          0          0          0   \n",
       "...                         ...        ...        ...        ...        ...   \n",
       "West Bank and Gaza            0          0          0          0          0   \n",
       "Winter Olympics 2022          0          0          0          0          0   \n",
       "Yemen                         0          0          0          0          0   \n",
       "Zambia                        0          0          0          0          0   \n",
       "Zimbabwe                      0          0          0          0          0   \n",
       "\n",
       "                      ...  2/28/2023  3/01/2023  3/02/2023  3/03/2023  \\\n",
       "Country_Region        ...                                               \n",
       "Afghanistan           ...     209322     209340     209358     209362   \n",
       "Albania               ...     334391     334408     334408     334427   \n",
       "Algeria               ...     271441     271448     271463     271469   \n",
       "Andorra               ...      47866      47875      47875      47875   \n",
       "Angola                ...     105255     105277     105277     105277   \n",
       "...                   ...        ...        ...        ...        ...   \n",
       "West Bank and Gaza    ...     703228     703228     703228     703228   \n",
       "Winter Olympics 2022  ...        535        535        535        535   \n",
       "Yemen                 ...      11945      11945      11945      11945   \n",
       "Zambia                ...     343012     343012     343079     343079   \n",
       "Zimbabwe              ...     263921     264127     264127     264127   \n",
       "\n",
       "                      3/04/2023  3/05/2023  3/06/2023  3/07/2023  3/08/2023  \\\n",
       "Country_Region                                                                \n",
       "Afghanistan              209369     209390     209406     209436     209451   \n",
       "Albania                  334427     334427     334427     334427     334443   \n",
       "Algeria                  271469     271477     271477     271490     271494   \n",
       "Andorra                   47875      47875      47875      47875      47890   \n",
       "Angola                   105277     105277     105277     105277     105288   \n",
       "...                         ...        ...        ...        ...        ...   \n",
       "West Bank and Gaza       703228     703228     703228     703228     703228   \n",
       "Winter Olympics 2022        535        535        535        535        535   \n",
       "Yemen                     11945      11945      11945      11945      11945   \n",
       "Zambia                   343079     343135     343135     343135     343135   \n",
       "Zimbabwe                 264127     264127     264127     264127     264276   \n",
       "\n",
       "                      3/09/2023  \n",
       "Country_Region                   \n",
       "Afghanistan              209451  \n",
       "Albania                  334457  \n",
       "Algeria                  271496  \n",
       "Andorra                   47890  \n",
       "Angola                   105288  \n",
       "...                         ...  \n",
       "West Bank and Gaza       703228  \n",
       "Winter Olympics 2022        535  \n",
       "Yemen                     11945  \n",
       "Zambia                   343135  \n",
       "Zimbabwe                 264276  \n",
       "\n",
       "[201 rows x 1143 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = doc.astype('int64')\n",
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pandas 라이브러리로 csv 파일 쓰기\n",
    "- pandas dataframe 데이터를 csv 파일로 저장하기 위해, to_csv() 함수 사용\n",
    "    ```\n",
    "    doc.to_csv(\"00_data/students_default.csv\")\n",
    "    ```\n",
    "\n",
    "- encoding 옵션 사용 가능\n",
    "    ```\n",
    "    doc.to_csv(\"00_data/students_default.csv\", encoding='utf-8-sig')\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.to_csv(\"COVID-19-master/final_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block\" style=\"border: 2px solid #1976D2;background-color:#E3F2FD;padding:5px;font-size:0.9em;\">\n",
    "본 자료는 저작권법 제25조 2항에 의해 보호를 받습니다. 본 자료를 외부에 공개하지 말아주세요.<br>\n",
    "본 강의만 잘 정리하면, 데이터 분석과 데이터 과학(머신러닝, 인공지능) 모두 가능합니다!<br>\n",
    "<b><a href=\"https://school.fun-coding.org/\">잔재미코딩</a> 에서 본 강의 기반 최적화된 로드맵도 확인하실 수 있습니다</b></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
