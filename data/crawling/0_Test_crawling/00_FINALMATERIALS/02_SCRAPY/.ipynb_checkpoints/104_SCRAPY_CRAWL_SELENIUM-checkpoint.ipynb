{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cec5b333-810c-46ce-9ff2-2eb5ead2b0de",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block\" style=\"border: 1px solid #455A64;background-color:#ECEFF1;\">\n",
    "본 자료 및 영상 컨텐츠는 저작권법 제25조 2항에 의해 보호를 받습니다. 본 컨텐츠 및 컨텐츠 일부 문구등을 외부에 공개, 게시하는 것을 금지합니다. 특히 자료에 대해서는 저작권법을 엄격하게 적용하겠습니다.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44448c85",
   "metadata": {},
   "source": [
    "### [참고] Scrapy 프로젝트6 (Scrapy with Selenium)\n",
    "\n",
    "#### 1. 프로젝트 생성 및 설정\n",
    "\n",
    "1. **새 Scrapy 프로젝트 생성**\n",
    "   ```bash\n",
    "   scrapy startproject daveleefun_project6\n",
    "   ```\n",
    "   이 명령어는 `daveleefun_project6`이라는 이름의 새 Scrapy 프로젝트를 생성합니다.\n",
    "\n",
    "2. **프로젝트 디렉토리로 이동**\n",
    "   ```bash\n",
    "   cd daveleefun_project6\n",
    "   ```\n",
    "   프로젝트 생성 후 해당 디렉토리로 이동합니다.\n",
    "\n",
    "3. **새 Spider 생성**\n",
    "   ```bash\n",
    "   scrapy genspider selenium_test davelee-fun.github.io\n",
    "   ```\n",
    "   `davelee-fun.github.io` 사이트를 크롤링할 목적으로 `selenium_test`라는 이름의 Spider를 생성합니다.\n",
    "\n",
    "#### 2. Selenium 설정\n",
    "\n",
    "1. **Selenium 설치**\n",
    "   Selenium과 Chrome WebDriver를 자동으로 관리해주는 `webdriver-manager` 는 설치되었다고 가정함\n",
    "   ```bash\n",
    "   pip install selenium webdriver-manager\n",
    "   ```\n",
    "\n",
    "2. **Spider 코드 작성**\n",
    "   Selenium을 사용하여 동적 컨텐츠가 포함된 웹페이지에서 데이터를 크롤링하기 위한 Spider 코드를 작성합니다.\n",
    "```python\n",
    "import scrapy\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "class SeleniumTestSpider(scrapy.Spider):\n",
    "    name = 'selenium_test'\n",
    "    allowed_domains = ['davelee-fun.github.io']\n",
    "    start_urls = ['http://davelee-fun.github.io/blog/TEST/index.html']\n",
    "\n",
    "    def __init__(self):\n",
    "        headlessoptions = webdriver.ChromeOptions()\n",
    "        headlessoptions.add_argument('headless')\n",
    "        driver = webdriver.Chrome(options=headlessoptions)\n",
    "\n",
    "    def parse(self, response):\n",
    "        self.driver.get(response.url)\n",
    "        time.sleep(2)  # 페이지가 완전히 로드될 때까지 기다립니다.\n",
    "        elements = self.driver.find_elements(By.CSS_SELECTOR, \".news\")\n",
    "        for element in elements:\n",
    "            yield { 'news': element.text }  # 데이터 아이템 정의\n",
    "        self.driver.quit()  # 크롤링 작업 완료 후 드라이버 종료\n",
    "```\n",
    "\n",
    "   - 이 코드는 Selenium WebDriver를 이용하여 페이지를 로드하고, 페이지가 완전히 로드될 때까지 기다린 후, 원하는 데이터를 추출합니다. Headless 모드를 설정하여 GUI 없이 백그라운드에서 크롬 브라우저를 실행합니다.\n",
    "\n",
    "#### 3. 크롤링 실행 및 결과 확인\n",
    "\n",
    "- 설정한 Selenium Spider를 실행하여 동적 웹페이지의 데이터를 크롤링합니다.\n",
    "  ```bash\n",
    "  scrapy crawl selenium_test -O results.json\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8333ec86-dd8a-4fb7-8fe5-4f0babaa45f1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block\" style=\"border: 1px solid #455A64;background-color:#ECEFF1;\">\n",
    "본 자료 및 영상 컨텐츠는 저작권법 제25조 2항에 의해 보호를 받습니다. 본 컨텐츠 및 컨텐츠 일부 문구등을 외부에 공개, 게시하는 것을 금지합니다. 특히 자료에 대해서는 저작권법을 엄격하게 적용하겠습니다.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
